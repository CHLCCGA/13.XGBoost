{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ensemble learning XGBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\CODE\\Lib\\site-packages\\_distutils_hack\\__init__.py:33: UserWarning: Setuptools is replacing distutils.\n",
      "  warnings.warn(\"Setuptools is replacing distutils.\")\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import sklearn\n",
    "import matplotlib as mlp\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import re, pip, conda\n",
    "import time\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Three elements of Boosting:\n",
    "\n",
    "- Loss function $L(y,\\hat{y})$: used to measure the difference between the model prediction results and the real results. <br>\n",
    "- Weak evaluator $f(x)$: (generally) decision tree, different boosting algorithms use different tree building processes. <br>\n",
    "- Comprehensive integration result $H(x)$: that is, how the integration algorithm specifically outputs the integration result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " **The balance between the learning ability of the tree model and the risk of overfitting is the balance between prediction accuracy and model complexity, as well as the balance between empirical risk and structural risk**\n",
    "\n",
    "\n",
    "> - **1. XGBoost adds a structural risk term to the loss function $L(y,\\hat{y})$ to form the objective function $O(y,\\hat{y})$**<br><br>\n",
    "> In AdaBoost and GBDT, our goal is to find the minimum value of the loss function $L(y,\\hat{y})$, that is, to minimize the difference between the predicted results and the real results. This process only cares about accuracy, not Care about complexity and overfitting. In order to deal with this problem, XGBoost draws experience from the pre-pruning process of decision trees, the anti-overfitting process of classic algorithms such as logistic regression, ridge regression, and Lasso, and adds a structural risk term to control overfitting to the loss function, and Define [$L(y,\\hat{y})$ + structural risk] as the objective function $O(y,\\hat{y})$. <br><br>\n",
    "> This change makes XGBoost different from other Boosting algorithms in many aspects: for example, XGBoost trains toward the goal of minimizing the objective function, rather than minimizing the loss function. For another example, XGBoost will give priority to using parameters in structural risk to control overfitting, unlike other tree ensemble models that rely on tree structure parameters (such as `max_depth`, `min_impurity_decrease`, etc.). <br><br>\n",
    "> - **2. Use a new impurity metric to incorporate complexity into branching rules**<br><br>\n",
    "> Among the algorithms we have learned before, no matter how the Boosting process evolves, the rules for building a single decision tree basically follow the CART tree process we have learned. In the classification tree, we use information gain to measure the leaves. In regression trees, we use MSE or Friedman MSE to measure the quality of leaves. This process has a mature pruning mechanism, high prediction accuracy, and can adapt to various scenarios, but it may build a tree with high complexity. <br><br>\n",
    "> In order to achieve a balance between accuracy and complexity, XGBoost resets the branching index **[Structure Score]** (written as Structure Score in the original paper, also known as Quality Score), and based on the structure The gain of structure score can force the decision tree to grow toward a simpler overall structure. <br><br>\n",
    "> This change allows XGBoost to use a tree-building process that is slightly different from traditional CART. At the same time, a large number of residuals or residual-like objects are used as intermediate variables in the tree-building process, so the mathematical process of XGBoost is more complex than other Boosting algorithms.\n",
    "\n",
    "- **Second, greatly reduce model complexity, improve model operating efficiency, and arm the algorithm into one more suitable for big data**\n",
    "在任意决策树的建树过程中，都需要对每一个特征上所有潜在的分枝节点进行不纯度计算，当数据量巨大时，这一计算将消耗巨量的时间，因此树集成模型的关键缺点之一就是计算缓慢，而这一缺点在实际工业环境当中是相当致命的。为了提升树模型的运算速度、同时又不极大地伤害模型的精确性，XGBoost使用多种优化技巧来实现效率提升：<br>\n",
    "\n",
    "> - **1. 使用估计贪婪算法、平行学习、分位数草图算法等方法构建了适用于大数据的全新建树流程**<br><br>\n",
    "> - **2. 使用感知缓存访问技术与核外计算技术，提升算法在硬件上的运算性能**<br><br>\n",
    "> - **3. 引入Dropout技术，为整体建树流程增加更多随机性、让算法适应更大数据**<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "XGBoost also retains some properties similar to gradient boosting trees, including:\n",
    "\n",
    "- **The output type of the weak evaluator is inconsistent with the output type of the ensemble algorithm**\n",
    "\n",
    "> For the AdaBoost or random forest algorithm, when the ensemble algorithm performs a regression task, the weak evaluator is also a regressor, and when the ensemble algorithm performs a classification task, the weak evaluator is also a classifier. But for GBDT and complex Boosting algorithms based on GBDT, regardless of whether the integrated algorithm is performing regression/classification/sorting tasks as a whole, the weak evaluator must be a regressor**. GBDT outputs specific classification results through the sigmoid or softmax function, but the actual weak evaluator must be a regressor, and the same is true for XGBoost.\n",
    "\n",
    "- **Fit negative gradient, and when the loss function is 0.5 times MSE, the fitting residual**\n",
    "\n",
    "> Any Boosting algorithm has the step of adaptively adjusting the weak estimator. In GBDT, what is used to build a weak estimator each time is the sample $X$ and the pseudo-residual difference (that is, the negative gradient) between the current integrated output $H(x_i)$ and the real label $y$. When the loss function is $\\frac{1}{2}MSE$, the negative gradient is mathematically equivalent to the residual (Residual), so **GBDT affects the subsequent weak evaluator structure by fitting the residual**. XGBoost also relies on fitting residuals to affect the subsequent weak estimator structure, but like GBDT, this needs to be proven mathematically.\n",
    "\n",
    "- **Sampling Thoughts**\n",
    "\n",
    "> GBDT draws on a large number of sampling ideas from the Bagging algorithm, and XGBoost also inherits this attribute. Therefore, in XGBoost, we can also sample samples and features to increase the independence between weak evaluators.\n",
    "\n",
    "Because of these similarities, we will see some familiar parameters in the parameters of XGBoost. If you are familiar with gradient boosting trees, many parameters of XGBoost should not be difficult to understand for you. It should be noted that, as a Boosting algorithm that was only officially proposed in 2014, XGBoost is an algorithm system independent of the classic algorithm, so the xgboost library needs to be installed separately."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install xgboost #安装xgboost库\n",
    "#!pip install --upgrade xgboost #更新xgboost库"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import xgboost as xgb "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2.0.3'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xgb.__version__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- # XGBoost regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "|类|说明|\n",
    "|:-:|:-:|\n",
    "|**XGBRegressor()**|实现xgboost回归|\n",
    "|**XGBClassifier()**|实现xgboost分类|\n",
    "|**XGBRanker()**|实现xgboost排序|\n",
    "|**XGBRFClassifier()**|基于xgboost库实现随机森林分类|\n",
    "|**XGBRFRegressor()**|基于xgboost库实现随机森林回归|"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from xgboost import XGBRegressor \n",
    "from sklearn.model_selection import cross_validate, KFold\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv(r\"D:\\Practice\\Machine Learning\\datasets\\House Price\\train_encode.csv\", index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = data.iloc[:,:-1]\n",
    "y = data.iloc[:,-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1460, 80)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count      1460.000000\n",
       "mean     180921.195890\n",
       "std       79442.502883\n",
       "min       34900.000000\n",
       "25%      129975.000000\n",
       "50%      163000.000000\n",
       "75%      214000.000000\n",
       "max      755000.000000\n",
       "Name: SalePrice, dtype: float64"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7681827467348319"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Xtrain, Xtest, Ytrain, Ytest = train_test_split(X, y, test_size=0.3, random_state=21)\n",
    "\n",
    "xgb_sk = XGBRegressor(random_state=21)\n",
    "xgb_sk.fit(Xtrain,Ytrain)\n",
    "xgb_sk.score(Xtest, Ytest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "xgb_sk = XGBRegressor(random_state=21)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 12 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   5 out of   5 | elapsed:    9.4s finished\n"
     ]
    }
   ],
   "source": [
    "cv = KFold(n_splits=5, shuffle=True,random_state=21)\n",
    "\n",
    "result_xgb_sk = cross_validate(xgb_sk,X,y,cv=cv,\n",
    "                               scoring=\"neg_root_mean_squared_error\",\n",
    "                               return_train_score=True,\n",
    "                               verbose=True,\n",
    "                               n_jobs=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'fit_time': array([0.60022521, 0.569098  , 0.59541702, 0.57928467, 0.54183531]),\n",
       " 'score_time': array([0.01377916, 0.00521708, 0.00480819, 0.01613235, 0.01572061]),\n",
       " 'test_score': array([-30324.87678271, -31122.22065422, -28712.33078882, -21450.69418462,\n",
       "        -27141.45317631]),\n",
       " 'train_score': array([-809.77246182, -684.66269697, -883.50186146, -875.8521187 ,\n",
       "        -974.72531804])}"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result_xgb_sk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def RMSE(result, name):\n",
    "    return abs(result[name].mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "845.7028913981958"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "RMSE(result_xgb_sk,\"train_score\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "27750.315117336217"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "RMSE(result_xgb_sk,\"test_score\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([8.26333184e-04, 2.12834612e-03, 8.12532101e-03, 1.54485530e-03,\n",
       "       3.29265394e-03, 0.00000000e+00, 0.00000000e+00, 1.04166195e-02,\n",
       "       8.34375247e-03, 0.00000000e+00, 6.22954394e-04, 5.31205384e-04,\n",
       "       9.73080005e-03, 9.57744254e-04, 2.16878587e-04, 4.28955769e-04,\n",
       "       3.75213567e-04, 3.67699683e-01, 5.65355876e-03, 7.52156600e-03,\n",
       "       4.85523697e-03, 6.16654288e-04, 3.88299959e-04, 2.42258189e-03,\n",
       "       6.88124448e-04, 2.03368231e-03, 1.36517768e-03, 9.92153585e-03,\n",
       "       8.29061551e-04, 4.28547821e-04, 3.72072458e-02, 1.12599344e-03,\n",
       "       1.68225938e-03, 1.37483701e-03, 1.07332589e-02, 6.06742804e-04,\n",
       "       4.89910948e-04, 1.04227941e-03, 2.09216047e-02, 0.00000000e+00,\n",
       "       1.42600539e-03, 1.32163782e-02, 3.49702721e-04, 9.48428456e-03,\n",
       "       1.59472823e-02, 6.03948080e-04, 4.15862463e-02, 3.98524664e-03,\n",
       "       1.28499628e-03, 7.59406528e-03, 1.72022637e-03, 2.81421118e-03,\n",
       "       1.25269502e-01, 5.51205017e-02, 4.16176580e-03, 3.74213257e-03,\n",
       "       8.31395388e-03, 2.09094747e-03, 1.46935284e-02, 2.22755806e-03,\n",
       "       3.31397518e-04, 1.27325520e-01, 4.73114243e-03, 5.99433435e-04,\n",
       "       2.23110639e-03, 6.67226675e-04, 3.77406622e-03, 3.60606634e-03,\n",
       "       4.24907630e-04, 7.56699825e-04, 3.33182048e-03, 1.89158507e-03,\n",
       "       0.00000000e+00, 3.08699062e-04, 1.57986447e-04, 1.59608506e-04,\n",
       "       1.18850742e-03, 6.86165236e-04, 1.38455001e-03, 3.66154034e-03],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xgb_sk = XGBRegressor(max_depth=5,random_state=1412).fit(X,y)\n",
    "xgb_sk.feature_importances_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<xgboost.core.Booster at 0x20d2c230f90>"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xgb_sk.get_booster()[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "100"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xgb_sk.get_num_boosting_rounds()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'objective': 'reg:squarederror',\n",
       " 'base_score': None,\n",
       " 'booster': None,\n",
       " 'callbacks': None,\n",
       " 'colsample_bylevel': None,\n",
       " 'colsample_bynode': None,\n",
       " 'colsample_bytree': None,\n",
       " 'device': None,\n",
       " 'early_stopping_rounds': None,\n",
       " 'enable_categorical': False,\n",
       " 'eval_metric': None,\n",
       " 'feature_types': None,\n",
       " 'gamma': None,\n",
       " 'grow_policy': None,\n",
       " 'importance_type': None,\n",
       " 'interaction_constraints': None,\n",
       " 'learning_rate': None,\n",
       " 'max_bin': None,\n",
       " 'max_cat_threshold': None,\n",
       " 'max_cat_to_onehot': None,\n",
       " 'max_delta_step': None,\n",
       " 'max_depth': 5,\n",
       " 'max_leaves': None,\n",
       " 'min_child_weight': None,\n",
       " 'missing': nan,\n",
       " 'monotone_constraints': None,\n",
       " 'multi_strategy': None,\n",
       " 'n_estimators': None,\n",
       " 'n_jobs': None,\n",
       " 'num_parallel_tree': None,\n",
       " 'random_state': 1412,\n",
       " 'reg_alpha': None,\n",
       " 'reg_lambda': None,\n",
       " 'sampling_method': None,\n",
       " 'scale_pos_weight': None,\n",
       " 'subsample': None,\n",
       " 'tree_method': None,\n",
       " 'validate_parameters': None,\n",
       " 'verbosity': None}"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xgb_sk.get_params()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Native code implementation of XGBoost regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Native code must use XGBoost’s custom data structure DMatrix**. This data structure can ensure that the xgboost algorithm runs faster and can be naturally migrated to run on the GPU. Structures such as lists, arrays, and Dataframes cannot be used. Native code, so the first step in using native code is to replace the data structure."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*class* `xgboost.DMatrix`(data, label=None, *, weight=None, base_margin=None, missing=None, silent=False, feature_names=None, feature_types=None, nthread=None, group=None, qid=None, label_lower_bound=None, label_upper_bound=None, feature_weights=None, enable_categorical=False)\n",
    "\n",
    "*function* `xgboost.train`(*params, dtrain, num_boost_round=10, *, evals=None, obj=None, feval=None, maximize=None, early_stopping_rounds=None, evals_result=None, verbose_eval=True, xgb_model=None, callbacks=None, custom_metric=None)\n",
    "\n",
    "*function* `xgboost.cv`(*params, dtrain, num_boost_round=10, nfold=3, stratified=False, folds=None, metrics=(), obj=None, feval=None, maximize=None, early_stopping_rounds=None, fpreproc=None, as_pandas=True, verbose_eval=None, show_stdv=True, seed=0, callbacks=None, shuffle=True, custom_metric=None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-Convert data to DMatrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Id</th>\n",
       "      <th>住宅类型</th>\n",
       "      <th>住宅区域</th>\n",
       "      <th>街道接触面积(英尺)</th>\n",
       "      <th>住宅面积</th>\n",
       "      <th>街道路面状况</th>\n",
       "      <th>巷子路面状况</th>\n",
       "      <th>住宅形状(大概)</th>\n",
       "      <th>住宅现状</th>\n",
       "      <th>水电气</th>\n",
       "      <th>...</th>\n",
       "      <th>半开放式门廊面积</th>\n",
       "      <th>泳池面积</th>\n",
       "      <th>泳池质量</th>\n",
       "      <th>篱笆质量</th>\n",
       "      <th>其他配置</th>\n",
       "      <th>其他配置的价值</th>\n",
       "      <th>销售月份</th>\n",
       "      <th>销售年份</th>\n",
       "      <th>销售类型</th>\n",
       "      <th>销售状态</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>36.0</td>\n",
       "      <td>327.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>51.0</td>\n",
       "      <td>498.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>39.0</td>\n",
       "      <td>702.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>31.0</td>\n",
       "      <td>489.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>55.0</td>\n",
       "      <td>925.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 80 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    Id  住宅类型  住宅区域  街道接触面积(英尺)   住宅面积  街道路面状况  巷子路面状况  住宅形状(大概)  住宅现状  水电气  \\\n",
       "0  0.0   5.0   3.0        36.0  327.0     1.0     0.0       3.0   3.0  0.0   \n",
       "1  1.0   0.0   3.0        51.0  498.0     1.0     0.0       3.0   3.0  0.0   \n",
       "2  2.0   5.0   3.0        39.0  702.0     1.0     0.0       0.0   3.0  0.0   \n",
       "3  3.0   6.0   3.0        31.0  489.0     1.0     0.0       0.0   3.0  0.0   \n",
       "4  4.0   5.0   3.0        55.0  925.0     1.0     0.0       0.0   3.0  0.0   \n",
       "\n",
       "   ...  半开放式门廊面积  泳池面积  泳池质量  篱笆质量  其他配置  其他配置的价值  销售月份  销售年份  销售类型  销售状态  \n",
       "0  ...       0.0   0.0   0.0   0.0   0.0      0.0   1.0   2.0   8.0   4.0  \n",
       "1  ...       0.0   0.0   0.0   0.0   0.0      0.0   4.0   1.0   8.0   4.0  \n",
       "2  ...       0.0   0.0   0.0   0.0   0.0      0.0   8.0   2.0   8.0   4.0  \n",
       "3  ...       0.0   0.0   0.0   0.0   0.0      0.0   1.0   0.0   8.0   0.0  \n",
       "4  ...       0.0   0.0   0.0   0.0   0.0      0.0  11.0   2.0   8.0   4.0  \n",
       "\n",
       "[5 rows x 80 columns]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_xgb = xgb.DMatrix(X,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<xgboost.core.DMatrix at 0x20d34bd0150>"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_xgb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "xgboost.core.DMatrix"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(data_xgb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "'DMatrix' object is not subscriptable",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[27], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m data_xgb[\u001b[38;5;241m0\u001b[39m]\n",
      "\u001b[1;31mTypeError\u001b[0m: 'DMatrix' object is not subscriptable"
     ]
    }
   ],
   "source": [
    "data_xgb[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "Xtrain,Xtest,Ytrain,Ytest = train_test_split(X,y,test_size=0.3,random_state=1412)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "dtrain = xgb.DMatrix(Xtrain, Ytrain)\n",
    "dtest = xgb.DMatrix(Xtest,Ytest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = {\"max_depth\":5, \"seed\":21}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "reg = xgb.train(params, data_xgb, num_boost_round=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\CODE\\Lib\\site-packages\\xgboost\\core.py:160: UserWarning: [13:59:53] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-0b3782d1791676daf-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:742: \n",
      "Parameters: { \"num_boost_round\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n"
     ]
    }
   ],
   "source": [
    "params = {\"num_boost_round\":100,\"max_depth\":5,\"seed\":1412}\n",
    "reg = xgb.train(params, data_xgb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([192319.78, 164022.9 , 214549.73, ..., 252041.53, 137165.7 ,\n",
       "       149061.48], dtype=float32)"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred = reg.predict(data_xgb)\n",
    "y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "15808.834219614408"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import mean_squared_error as MSE\n",
    "MSE(y,y_pred,squared=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = {\"max_depth\":5, \"seed\":21}\n",
    "result = xgb.cv(params,data_xgb,num_boost_round=100,\n",
    "                nfold=5,\n",
    "                seed=21)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>train-rmse-mean</th>\n",
       "      <th>train-rmse-std</th>\n",
       "      <th>test-rmse-mean</th>\n",
       "      <th>test-rmse-std</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>60407.440564</td>\n",
       "      <td>775.323852</td>\n",
       "      <td>61958.720138</td>\n",
       "      <td>3101.365692</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>46916.424100</td>\n",
       "      <td>632.389252</td>\n",
       "      <td>50230.884495</td>\n",
       "      <td>2666.308721</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>37380.302022</td>\n",
       "      <td>388.816593</td>\n",
       "      <td>42602.758725</td>\n",
       "      <td>2967.382971</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>30545.218617</td>\n",
       "      <td>324.799826</td>\n",
       "      <td>37610.212116</td>\n",
       "      <td>2815.912726</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>25584.269884</td>\n",
       "      <td>299.427683</td>\n",
       "      <td>34395.495393</td>\n",
       "      <td>2854.163918</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>2411.859324</td>\n",
       "      <td>169.804205</td>\n",
       "      <td>28009.412688</td>\n",
       "      <td>3915.186244</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>2362.420789</td>\n",
       "      <td>153.980358</td>\n",
       "      <td>28011.563637</td>\n",
       "      <td>3923.116978</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>2323.544040</td>\n",
       "      <td>159.753160</td>\n",
       "      <td>28008.789517</td>\n",
       "      <td>3926.267356</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>2290.508689</td>\n",
       "      <td>163.230855</td>\n",
       "      <td>28015.371320</td>\n",
       "      <td>3926.801498</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>2246.698421</td>\n",
       "      <td>162.265996</td>\n",
       "      <td>28013.290433</td>\n",
       "      <td>3926.062865</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    train-rmse-mean  train-rmse-std  test-rmse-mean  test-rmse-std\n",
       "0      60407.440564      775.323852    61958.720138    3101.365692\n",
       "1      46916.424100      632.389252    50230.884495    2666.308721\n",
       "2      37380.302022      388.816593    42602.758725    2967.382971\n",
       "3      30545.218617      324.799826    37610.212116    2815.912726\n",
       "4      25584.269884      299.427683    34395.495393    2854.163918\n",
       "..              ...             ...             ...            ...\n",
       "95      2411.859324      169.804205    28009.412688    3915.186244\n",
       "96      2362.420789      153.980358    28011.563637    3923.116978\n",
       "97      2323.544040      159.753160    28008.789517    3926.267356\n",
       "98      2290.508689      163.230855    28015.371320    3926.801498\n",
       "99      2246.698421      162.265996    28013.290433    3926.062865\n",
       "\n",
       "[100 rows x 4 columns]"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1920x1440 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(dpi=300)\n",
    "plt.plot(result[\"train-rmse-mean\"])\n",
    "plt.plot(result[\"test-rmse-mean\"])\n",
    "plt.legend([\"train\",\"test\"])\n",
    "plt.title(\"xgboost 5fold cv\");"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### xgboost clasification"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "XGBoost implements the regression algorithm by default, so when performing classification, we need to actively declare the type of algorithm. xgboost determines the task type through the loss function used by the current algorithm, that is, through the `objective` parameters filled in params to determine the task type. When the regression task is no longer performed, the evaluation indicators of the model will also change, so xgboost classification will require more parameters. Dozens of different options can be entered in the `objective` parameter, the common ones are:\n",
    "\n",
    "- for regression\n",
    "> - **reg:squarederror**: squared loss, that is, $\\frac{1}{2}(y - \\hat{y})^2$, where 1/2 is for simplicity of calculation<br><br>\n",
    "> - **reg:squaredlogerror**: Squared logarithm loss, that is, $\\frac{1}{2}[log(\\hat{y} + 1) - log(y + 1)]^2$, where 1 /2 is for ease of calculation\n",
    "\n",
    "- for classification\n",
    "> - **binary:logistic**: binary cross-entropy loss. When using this loss, the `predict` interface outputs the probability. If you are not familiar with this loss, you will need to learn the logistic regression algorithm. <br><br>\n",
    "> - **binary:logitraw**: binary cross-entropy loss. When using this loss, `predict` will output the value before performing the sigmoid change<br><br>\n",
    "> - **multi:softmax**: Multi-class cross entropy loss. When using this loss, the `predict` interface outputs specific categories. If you are not familiar with this loss, you need to learn AdaBoost and GBDT. <br><br>\n",
    "> - **multi:softprob**: Multi-class cross entropy, when this loss is applied, the `predict` interface outputs the probability of each category of each sample\n",
    "\n",
    "In addition, there are many loss functions used in sorting algorithms and counting algorithms. xgboost is suitable for almost all differentiable loss functions. Different loss functions will affect the output of `predict`, but will not affect the output of the cross-validation method `xgb.cv`. When nothing is filled in, the default value of the parameter `objective` is `reg:squarederror`. Next let's take a look at the implementation of the xgboost classifier:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_breast_cancer, load_digits\n",
    "\n",
    "X_binary = load_breast_cancer().data\n",
    "y_binary = load_breast_cancer().target\n",
    "data_binary = xgb.DMatrix(X_binary, y_binary)\n",
    "\n",
    "X_multi = load_digits().data\n",
    "y_multi = load_digits().target\n",
    "data_multi = xgb.DMatrix(X_multi, y_multi)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "params1 = {\"seed\":21, \"objective\":\"binary:logistic\",\n",
    "           \"eval_metric\":\"logloss\"\n",
    "           }\n",
    "clf_binary = xgb.train(params1, data_binary, num_boost_round=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "params2 = {\"seed\":21, \"objective\":\"multi:softmax\",\n",
    "           \"eval_metric\":\"mlogloss\",\n",
    "           \"num_class\":10}\n",
    "clf_multi = xgb.train(params2, data_multi, num_boost_round=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_binary = clf_binary.predict(data_binary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_multi = clf_multi.predict(data_multi)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([5.9830486e-03, 1.0785054e-03, 2.8278260e-04, 1.7240757e-02,\n",
       "       8.8689197e-03, 2.0348135e-02, 8.1676582e-05, 4.3557968e-04,\n",
       "       1.5153858e-03, 5.1954496e-03, 1.1665462e-02, 3.4424273e-04,\n",
       "       7.8352279e-04, 6.0624103e-03, 1.3893890e-02, 4.8467741e-04,\n",
       "       9.8429613e-05, 1.8938415e-04, 1.3668074e-04, 9.9775141e-01],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred_binary[:20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0., 1., 2., ..., 8., 9., 8.], dtype=float32)"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred_multi "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score as ACC #当返回具体类别时，可以使用准确率\n",
    "from sklearn.metrics import log_loss as logloss #当返回概率时，则必须使用交叉熵损失"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 1, 0, 1, 1, 1, 1, 1, 0, 0, 1, 0, 0, 1, 1, 1, 1, 0, 1, 0, 0,\n",
       "       1, 1, 1, 1, 0, 1, 0, 0, 1, 0, 1, 0, 0, 1, 1, 1, 0, 0, 1, 0, 0, 0,\n",
       "       1, 1, 1, 0, 1, 1, 0, 0, 1, 1, 1, 0, 0, 1, 1, 1, 1, 0, 1, 1, 0, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 1, 0, 0, 1, 1, 1, 0, 0, 1, 0, 1, 0,\n",
       "       0, 1, 0, 0, 1, 1, 0, 1, 1, 0, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 0, 1, 1, 1, 1, 0, 0, 1, 0, 1, 1, 0, 0, 1, 1, 0, 0, 1, 1, 1,\n",
       "       1, 0, 1, 1, 0, 0, 0, 1, 0, 1, 0, 1, 1, 1, 0, 1, 1, 0, 0, 1, 0, 0,\n",
       "       0, 0, 1, 0, 0, 0, 1, 0, 1, 0, 1, 1, 0, 1, 0, 0, 0, 0, 1, 1, 0, 0,\n",
       "       1, 1, 1, 0, 1, 1, 1, 1, 1, 0, 0, 1, 1, 0, 1, 1, 0, 0, 1, 0, 1, 1,\n",
       "       1, 1, 0, 1, 1, 1, 1, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 1, 1, 1, 1, 1, 1, 0, 1, 0, 1, 1, 0, 1, 1, 0, 1, 0, 0, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 0, 0,\n",
       "       0, 1, 1, 1, 1, 0, 1, 0, 1, 0, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 0,\n",
       "       0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 0, 0, 0, 1, 0, 0,\n",
       "       1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 0, 1, 1, 1, 0, 1, 1, 0, 0, 1, 1,\n",
       "       1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 0, 1, 1, 0,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 0, 0, 1, 0, 1, 1, 1, 1,\n",
       "       1, 0, 1, 1, 0, 1, 0, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0,\n",
       "       1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1,\n",
       "       1, 1, 1, 0, 1, 0, 1, 1, 0, 1, 1, 1, 1, 1, 0, 0, 1, 0, 1, 0, 1, 1,\n",
       "       1, 1, 1, 0, 1, 1, 0, 1, 0, 1, 0, 0, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 0, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 1])"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(y_pred_binary > 0.5).astype(\"int\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ACC(y_binary,(y_pred_binary > 0.5).astype(int)) #对二分类计算准确率，则必须先转换为类别"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ACC(y_multi, y_pred_multi)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.004643990703670779"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logloss(y_binary,y_pred_binary) #只有二分类输出了概率，因此可以查看交叉熵损失"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "params2 = {\"seed\":21\n",
    "           , \"objective\":\"multi:softmax\" #无论填写什么损失函数都不影响交叉验证的评估指标\n",
    "           , \"num_class\":10}\n",
    "result = xgb.cv(params2,data_multi,num_boost_round=100\n",
    "                ,metrics = (\"mlogloss\") #交叉验证的评估指标由cv中的参数metrics决定\n",
    "                ,nfold=5 \n",
    "                ,seed=21 \n",
    "                )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>train-mlogloss-mean</th>\n",
       "      <th>train-mlogloss-std</th>\n",
       "      <th>test-mlogloss-mean</th>\n",
       "      <th>test-mlogloss-std</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.228107</td>\n",
       "      <td>0.001116</td>\n",
       "      <td>1.321186</td>\n",
       "      <td>0.014580</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.870656</td>\n",
       "      <td>0.000678</td>\n",
       "      <td>1.005905</td>\n",
       "      <td>0.018784</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.643234</td>\n",
       "      <td>0.001704</td>\n",
       "      <td>0.800929</td>\n",
       "      <td>0.016008</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.484985</td>\n",
       "      <td>0.001172</td>\n",
       "      <td>0.655639</td>\n",
       "      <td>0.017381</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.370800</td>\n",
       "      <td>0.001917</td>\n",
       "      <td>0.548040</td>\n",
       "      <td>0.019544</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>0.003914</td>\n",
       "      <td>0.000007</td>\n",
       "      <td>0.103018</td>\n",
       "      <td>0.022063</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>0.003903</td>\n",
       "      <td>0.000007</td>\n",
       "      <td>0.102995</td>\n",
       "      <td>0.022097</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>0.003892</td>\n",
       "      <td>0.000008</td>\n",
       "      <td>0.103033</td>\n",
       "      <td>0.022146</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>0.003882</td>\n",
       "      <td>0.000008</td>\n",
       "      <td>0.102920</td>\n",
       "      <td>0.022162</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>0.003871</td>\n",
       "      <td>0.000009</td>\n",
       "      <td>0.102847</td>\n",
       "      <td>0.022141</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    train-mlogloss-mean  train-mlogloss-std  test-mlogloss-mean  \\\n",
       "0              1.228107            0.001116            1.321186   \n",
       "1              0.870656            0.000678            1.005905   \n",
       "2              0.643234            0.001704            0.800929   \n",
       "3              0.484985            0.001172            0.655639   \n",
       "4              0.370800            0.001917            0.548040   \n",
       "..                  ...                 ...                 ...   \n",
       "95             0.003914            0.000007            0.103018   \n",
       "96             0.003903            0.000007            0.102995   \n",
       "97             0.003892            0.000008            0.103033   \n",
       "98             0.003882            0.000008            0.102920   \n",
       "99             0.003871            0.000009            0.102847   \n",
       "\n",
       "    test-mlogloss-std  \n",
       "0            0.014580  \n",
       "1            0.018784  \n",
       "2            0.016008  \n",
       "3            0.017381  \n",
       "4            0.019544  \n",
       "..                ...  \n",
       "95           0.022063  \n",
       "96           0.022097  \n",
       "97           0.022146  \n",
       "98           0.022162  \n",
       "99           0.022141  \n",
       "\n",
       "[100 rows x 4 columns]"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "params3 = {\"seed\":21\n",
    "           , \"objective\":\"multi:softmax\" #无论填写什么损失函数都不影响交叉验证的评估指标\n",
    "           , \"num_class\":10}\n",
    "result = xgb.cv(params3,data_multi,num_boost_round=100\n",
    "                ,metrics = (\"mlogloss\",\"merror\")\n",
    "                ,nfold=5 \n",
    "                ,seed=21 \n",
    "                )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>train-mlogloss-mean</th>\n",
       "      <th>train-mlogloss-std</th>\n",
       "      <th>train-merror-mean</th>\n",
       "      <th>train-merror-std</th>\n",
       "      <th>test-mlogloss-mean</th>\n",
       "      <th>test-mlogloss-std</th>\n",
       "      <th>test-merror-mean</th>\n",
       "      <th>test-merror-std</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.228107</td>\n",
       "      <td>0.001116</td>\n",
       "      <td>0.029634</td>\n",
       "      <td>0.004378</td>\n",
       "      <td>1.321186</td>\n",
       "      <td>0.014580</td>\n",
       "      <td>0.116291</td>\n",
       "      <td>0.015276</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.870656</td>\n",
       "      <td>0.000678</td>\n",
       "      <td>0.013774</td>\n",
       "      <td>0.003279</td>\n",
       "      <td>1.005905</td>\n",
       "      <td>0.018784</td>\n",
       "      <td>0.092365</td>\n",
       "      <td>0.011769</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.643234</td>\n",
       "      <td>0.001704</td>\n",
       "      <td>0.008487</td>\n",
       "      <td>0.002388</td>\n",
       "      <td>0.800929</td>\n",
       "      <td>0.016008</td>\n",
       "      <td>0.079571</td>\n",
       "      <td>0.005649</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.484985</td>\n",
       "      <td>0.001172</td>\n",
       "      <td>0.005148</td>\n",
       "      <td>0.001433</td>\n",
       "      <td>0.655639</td>\n",
       "      <td>0.017381</td>\n",
       "      <td>0.074006</td>\n",
       "      <td>0.006891</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.370800</td>\n",
       "      <td>0.001917</td>\n",
       "      <td>0.002922</td>\n",
       "      <td>0.000682</td>\n",
       "      <td>0.548040</td>\n",
       "      <td>0.019544</td>\n",
       "      <td>0.066770</td>\n",
       "      <td>0.006739</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>0.003914</td>\n",
       "      <td>0.000007</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.103018</td>\n",
       "      <td>0.022063</td>\n",
       "      <td>0.032275</td>\n",
       "      <td>0.008354</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>0.003903</td>\n",
       "      <td>0.000007</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.102995</td>\n",
       "      <td>0.022097</td>\n",
       "      <td>0.031718</td>\n",
       "      <td>0.008891</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>0.003892</td>\n",
       "      <td>0.000008</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.103033</td>\n",
       "      <td>0.022146</td>\n",
       "      <td>0.032275</td>\n",
       "      <td>0.008354</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>0.003882</td>\n",
       "      <td>0.000008</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.102920</td>\n",
       "      <td>0.022162</td>\n",
       "      <td>0.032275</td>\n",
       "      <td>0.008354</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>0.003871</td>\n",
       "      <td>0.000009</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.102847</td>\n",
       "      <td>0.022141</td>\n",
       "      <td>0.032275</td>\n",
       "      <td>0.008354</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows × 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    train-mlogloss-mean  train-mlogloss-std  train-merror-mean  \\\n",
       "0              1.228107            0.001116           0.029634   \n",
       "1              0.870656            0.000678           0.013774   \n",
       "2              0.643234            0.001704           0.008487   \n",
       "3              0.484985            0.001172           0.005148   \n",
       "4              0.370800            0.001917           0.002922   \n",
       "..                  ...                 ...                ...   \n",
       "95             0.003914            0.000007           0.000000   \n",
       "96             0.003903            0.000007           0.000000   \n",
       "97             0.003892            0.000008           0.000000   \n",
       "98             0.003882            0.000008           0.000000   \n",
       "99             0.003871            0.000009           0.000000   \n",
       "\n",
       "    train-merror-std  test-mlogloss-mean  test-mlogloss-std  test-merror-mean  \\\n",
       "0           0.004378            1.321186           0.014580          0.116291   \n",
       "1           0.003279            1.005905           0.018784          0.092365   \n",
       "2           0.002388            0.800929           0.016008          0.079571   \n",
       "3           0.001433            0.655639           0.017381          0.074006   \n",
       "4           0.000682            0.548040           0.019544          0.066770   \n",
       "..               ...                 ...                ...               ...   \n",
       "95          0.000000            0.103018           0.022063          0.032275   \n",
       "96          0.000000            0.102995           0.022097          0.031718   \n",
       "97          0.000000            0.103033           0.022146          0.032275   \n",
       "98          0.000000            0.102920           0.022162          0.032275   \n",
       "99          0.000000            0.102847           0.022141          0.032275   \n",
       "\n",
       "    test-merror-std  \n",
       "0          0.015276  \n",
       "1          0.011769  \n",
       "2          0.005649  \n",
       "3          0.006891  \n",
       "4          0.006739  \n",
       "..              ...  \n",
       "95         0.008354  \n",
       "96         0.008891  \n",
       "97         0.008354  \n",
       "98         0.008354  \n",
       "99         0.008354  \n",
       "\n",
       "[100 rows x 8 columns]"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "from xgboost import XGBClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = XGBClassifier()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'objective': 'binary:logistic',\n",
       " 'base_score': None,\n",
       " 'booster': None,\n",
       " 'callbacks': None,\n",
       " 'colsample_bylevel': None,\n",
       " 'colsample_bynode': None,\n",
       " 'colsample_bytree': None,\n",
       " 'device': None,\n",
       " 'early_stopping_rounds': None,\n",
       " 'enable_categorical': False,\n",
       " 'eval_metric': None,\n",
       " 'feature_types': None,\n",
       " 'gamma': None,\n",
       " 'grow_policy': None,\n",
       " 'importance_type': None,\n",
       " 'interaction_constraints': None,\n",
       " 'learning_rate': None,\n",
       " 'max_bin': None,\n",
       " 'max_cat_threshold': None,\n",
       " 'max_cat_to_onehot': None,\n",
       " 'max_delta_step': None,\n",
       " 'max_depth': None,\n",
       " 'max_leaves': None,\n",
       " 'min_child_weight': None,\n",
       " 'missing': nan,\n",
       " 'monotone_constraints': None,\n",
       " 'multi_strategy': None,\n",
       " 'n_estimators': None,\n",
       " 'n_jobs': None,\n",
       " 'num_parallel_tree': None,\n",
       " 'random_state': None,\n",
       " 'reg_alpha': None,\n",
       " 'reg_lambda': None,\n",
       " 'sampling_method': None,\n",
       " 'scale_pos_weight': None,\n",
       " 'subsample': None,\n",
       " 'tree_method': None,\n",
       " 'validate_parameters': None,\n",
       " 'verbosity': None}"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.get_params()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = XGBClassifier(objective=\"multi:softmax\",\n",
    "                    eval_metric=\"mlogloss\",\n",
    "                    num_class=10 #,use_label_encoder=False\n",
    "                    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = clf.fit(X_multi, y_multi)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 1, 2, ..., 8, 9, 8])"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.predict(X_multi)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1797, 10)"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.predict_proba(X_multi).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.score(X_multi, y_multi)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### parameters of XGBoost"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "|类型|参数|\n",
    "|-|-|\n",
    "|**迭代过程/目标函数**|**params**: eta, base_score, objective, <font color=\"green\">**lambda, gamma, alpha, max_delta_step**</font><br>**xgb.train()**: num_boost_round|\n",
    "|**弱评估器结构**|**params**: max_depth, <font color=\"green\">**booster, min_child_weight**</font>|\n",
    "|**dart树**|**params**: <font color=\"green\">**sample_type, normalized_type, rate_drop, one_drop, skip_drop**</font>|\n",
    "|**弱评估器的训练数据**|**params**: subsample, <font color=\"green\">**sampling_method, colsamle_bytree, colsample_bylevel, colsample_bynode**</font>|\n",
    "|**提前停止**|**xgb.train()**: <font color=\"green\">**early_stopping_rounds, evals**</font>, eval_metric|\n",
    "|**其他**|**params**: seed, <font color=\"green\">**verbosity, scale_pos_weight, nthread**</font>|"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$H_k(x_i) = H_{k-1}(x_i) + \\boldsymbol{\\color{red}\\eta} f_k(x_i)$$\n",
    "\n",
    "This learning rate parameter controls the growth rate of $H(x_i)$ during the Boosting integration process and is a very critical parameter. When the learning rate is large, $H(x_i)$ grows faster and we need less `num_boost_round`. When the learning rate is small, $H(x_i)$ grows slower and we need `num_boost_round`. ` is more, so the boosting algorithm often needs to make a trade-off between `num_boost_round` and `eta`. In XGBoost, the default value of `num_boost_round` is 10 and the default value of `eta` is 0.3\n",
    "\n",
    "- `base_score`\n",
    "\n",
    "\n",
    "When we build our first weak evaluator we have:\n",
    "\n",
    "$$H_1(x_i) = H_{0}(x_i) + \\eta f_1(x_i)$$\n",
    "\n",
    "Since there is no 0th tree, the value of $H_0(x_i)$ needs to be determined separately during the mathematical process and the specific implementation of the algorithm, and this value is determined by `base_score`. In xgboost, we can output **any value** to `base_score`, but operations similar to the input evaluator in GBDT are not supported. When not filled in, the default value of this parameter is 0.5, that is, 0.5 is set as the starting value for all samples. When the number of iterations is large enough and the amount of data is large enough, it makes little sense to adjust $H_0(x_i)$ of the algorithm, so we basically will not adjust this parameter.\n",
    "- Parameter `max_delta_step`\n",
    "\n",
    "During the iteration process, XGBoost has a unique parameter `max_delta_step`. This parameter represents the maximum $\\eta f_k(x_i)$ allowed at each iteration. When the parameter `max_delta_step` is set to 0, it means that there is no limit on the size of $\\eta f_k(x_i)$ for each iteration. If the parameter is set to a positive number C, it means $\\eta f_k(x_i) \\leq C$, otherwise let the algorithm execute:\n",
    "\n",
    "$$H_k(x_i) = H_{k-1}(x_i) + C$$\n",
    "\n",
    "Usually this parameter is not needed, but sometimes this parameter is effective for extremely imbalanced data. If the sample is extremely unbalanced, you can try setting a number between 1 and 10 in this parameter.\n",
    "\n",
    "Summarize:\n",
    "\n",
    "|Parameter meaning|Native code|sklearn API|\n",
    "|:-:|:-:|:-:|\n",
    "|Number of iterations/number of trees|**num_boost_round**<br>(xgb.train)|**n_estimators**|\n",
    "|Learning rate|**eta**<br>(params)|**learning_rate**|\n",
    "|Initial iteration value|**base_score**<br>(params)|**base_score**|\n",
    "|The maximum iteration value allowed in an iteration|**max_delta_step**<br>(params)|**max_delta_step**|"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Objective function of xgboost"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**xgboost runs in the direction that minimizes the objective function**\n",
    "**But in the definition of XGBoost, the objective function is for each tree, not for a sample or the entire algorithm** For any tree $f_k$, the objective function has two components, one part is arbitrary A micro loss function that controls the **empirical risk** of the model. Numerically speaking, it is equal to the sum of the loss functions on all samples in the current tree, where the loss of a single sample is $l(y_i,\\hat{y_i})$. The other part is $\\Omega(f_k)$ that controls the complexity of the model, which controls the **structural risk** of the current tree.\n",
    "\n",
    "$Obj_k = \\sum_{i=1}^Ml(y_i,\\hat{y_i}) + \\Omega(f_k)$\n",
    ">其中$M$表示现在这棵树上一共使用了M个样本，$l$表示单一样本的损失函数。当模型迭代完毕之后，最后一棵树上的目标函数就是整个XGBoost算法的目标函数。\n",
    "- **Experiential Risk**: The deeper the model learns from the data, the smaller the loss (the smaller the empirical risk). The more superficially the model learns the data, the greater the loss (the greater the empirical risk).\n",
    "\n",
    "- **Structural Risk**: The more complex the tree structure and the higher the model complexity, the greater the risk of overfitting (the greater the structural risk). The simpler the tree model structure, the lower the model complexity, and the smaller the risk of overfitting (the smaller the structural risk).\n",
    "Generally speaking, the model needs to reach a certain complexity to ensure a small loss. However, if you only pursue the smallest empirical risk, it will easily lead to overfitting. On the contrary, if you only pursue low model complexity and low structural risk, the model will easily fall into the dilemma of under-fitting and the loss function will be too high. Therefore, it is very important to balance structural risk and empirical risk. XGBoost operates in the direction of minimizing the objective function, which can ensure that during the iteration process, the empirical risk and structural risk will not become too large, so the loss of the model will not be too great, and at the same time, it will not be too easy to overfit."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the specific formula, the structural risk $\\Omega(f_k)$ is composed of two parts. One part is the $\\gamma T$ that controls the tree structure, and the other part is the regular term:\n",
    "\n",
    "$\\Omega(f_k) = \\boldsymbol{\\color{red}\\gamma} T + \\frac{1}{2}\\boldsymbol{\\color{red}\\lambda}\\sum_{j=1}^Tw_j^2 + \\boldsymbol{\\color{red}\\alpha}\\sum_{j=1}^Tw_j$\n",
    "\n",
    "Among them, $\\gamma$, $\\lambda$ and $\\alpha$ are coefficients that can be set freely, and $T$ represents the total number of leaves on the current $k$ tree, and $w_j$ represents the current tree. Leaf weights of $j$ leaves. **Leaf weight is a very critical factor in the XGBoost mathematical system. It is actually the predicted value of the current leaf $j$**. This indicator has a greater relationship with the label dimension of the data. Therefore, when the absolute value of the label The larger the value, the larger the value of $w_j$ will tend to be. Therefore, there are two regular terms: the L2 regular term using squares and the L1 regular term using absolute values, so the complete objective function expression is:\n",
    "\n",
    "$$Obj_k = \\sum_{i=1}^Ml(y_i,\\hat{y_i}) + \\boldsymbol{\\color{red}\\gamma} T + \\frac{1}{2}\\boldsymbol{\\color{ red}\\lambda}\\sum_{j=1}^Tw_j^2 + \\boldsymbol{\\color{red}\\alpha}\\sum_{j=1}^Tw_j$$\n",
    "\n",
    "It is not difficult to find that all freely set coefficients are related to structural risk. These three coefficients also correspond to the three parameters in xgboost: `gamma`, `alpha` and `lambda`.\n",
    "\n",
    "- Parameter `gamma`: multiplied by the total number of leaves of a tree $T$, the coefficient that imposes a penalty on the objective function according to the total number of leaves. The default value is 0, and any number between [0, ∞] can be filled in. When the total number of leaves is fixed, the larger `gamma` is, the larger the structural risk term will be; at the same time, when `gamma` is constant, the more total number of leaves and the greater the complexity of the model, the larger the structural risk term will be. In the above two cases, the penalty on the objective function will be greater, so **increasing `gamma` can control overfitting**. <br><br>\n",
    "- Parameters `alpha` and `lambda`: multiplied before the regular term, the coefficient that imposes a penalty on the objective function according to the size of the leaf weight is the coefficient of the regular term. The default value of `lambda` is 1 and the default value of `alpha` is 0, so xgboost uses L2 regularization by default. Normally, we wouldn't use both regularizers at the same time, but we can try that. $\\sum_{j=1}^Tw_j$ is the sum of the output values ​​of all leaves on the current tree, so when there are more leaves on the tree and the complexity of the model becomes greater, $\\sum_{j=1}^Tw_j$ The natural value will naturally be larger, so when the regularization coefficient is fixed, the higher the complexity of the model, the heavier the penalty on the overall objective function. When $w$ is fixed, the larger the coefficient of the regular term, the larger the overall objective function. Therefore, increasing `alpha` or `lambda` can control overfitting**.\n",
    "\n",
    "|参数含义|原生代码|sklearn API|\n",
    "|:-:|:-:|:-:|\n",
    "|乘在叶子节点数量前的系数|**gamma**<br>(params)|**gamma**|\n",
    "|L2正则项系数|**lambda**<br>(params)|**reg_lambda**|\n",
    "|L1正则项系数|**alpha**<br>(params)|**reg_alpha**|"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "可见，现在`lambda`比`gamma`有效。\n",
    "|类型|参数|\n",
    "|---|---|\n",
    "|**迭代过程/损失函数**|num_boost_round：集成算法中弱分类器数量，对Boosting算法而言为实际迭代次数<br><br>eta：Boosting算法中的学习率，影响弱分类器结果的加权求和过程<br><br><font color=\"green\">**objective**</font>：选择需要优化的损失函数<br><br><font color=\"green\">**base_score**</font>：初始化预测结果$H_0$的设置<br><br><font color=\"green\">**max_delta_step**</font>：一次迭代中所允许的最大迭代值<br><br><font color=\"green\">**gamma**</font>：乘在叶子数量前的系数，放大可控制过拟合<br><br><font color=\"green\">**lambda**</font>：L2正则项系数，放大可控制过拟合<br><br><font color=\"green\">**alpha**</font>：L1正则项系数，放大可控制过拟合|"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### XGBoost weak estimator\n",
    "\n",
    "#### three estimator & DART"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- `booster`：\n",
    "> \"gbtree\",\"gblinear\",\"dart\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> 输入\"gbtree\"表示使用遵循XGBoost规则的CART树，我们之前提到的XGBoost在GBDT上做出的改善基本都是针对这一类型的树。这一类型的树又被称为“XGBoost独有树”，XGBoost Unique Tree。<br><br>\n",
    "> 输入\"dart\"表示使用抛弃提升树，DART是Dropout Multiple Additive Regression Tree的简称。这种建树方式受深度学习中的Dropout技巧启发，在建树过程中会随机抛弃一些树的结果，可以更好地防止过拟合。在数据量巨大、过拟合容易产生时，DART树经常被使用，但由于会随机地抛弃到部分树，可能会伤害模型的学习能力，同时可能会需要更长的迭代时间。<br><br>\n",
    "> 输入\"gblinear\"则表示使用线性模型，当弱评估器类型是\"gblinear\"而损失函数是MSE时，表示使用xgboost方法来集成线性回归。当弱评估器类型是\"gblinear\"而损失函数是交叉熵损失时，则代表使用xgboost来集成逻辑回归。<br><br>\n",
    "> 每一种弱评估器都有自己的params列表，例如只有树模型才会有学习率等参数，只有DART树才会有抛弃率等参数。评估器必须与params中的参数相匹配，否则一定会报错。其中，由于DART树是从gbtree的基础上衍生而来，因此gbtree的所有参数DART树都可以使用。\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When a new tree is built in the $k$ th iteration, the result after the iteration is equal to the result of all previous ${k-1}$ trees plus the result of the newly established tree:\n",
    "\n",
    "$$H_k(x_i) = H_{k-1}(x_i) + \\boldsymbol{\\color{red}\\eta} f_k(x_i)$$\n",
    "\n",
    "The DART tree will randomly discard some trees before **each iteration**, that is, these trees will not be involved in the calculation of $H_{k-1}(x_i)$. This method of random abandonment is called \"Dropout\" . For example, assuming there are 5 trees in total, the results are as follows:\n",
    "\n",
    "||k=1|k=2|k=3|k=4|k=5|\n",
    "|:-:|:-:|:-:|:-:|:-:|:-:|\n",
    "|$\\eta f_k(x_i)$|1|0.8|0.6|0.5|0.3|\n",
    "\n",
    "When building the sixth tree, $H_{k-1}(x_i)$ = 1+0.8+0.6+0.5+0.3 = 3.2 of the ordinary  tree. For the DART tree, we can think of setting the drop rate `rate_drop`. Assuming the drop rate is 0.2, the DART tree will randomly sample one tree from 5 trees and drop it. Assuming that the second tree is abandoned, $H_{k-1}(x_i)$ of the DART tree = 1+0.6+0.5+0.3 = 2.4. By affecting $H_{k-1}(x_i)$, the DART tree affects the loss function and the output result of the entire algorithm $H(x)$, which can greatly affect the entire xgboost in each iteration. direction.\n",
    "\n",
    "In general anti-overfitting methods, we can only prune the tree in a fancy way from the perspective of the learning ability of a single tree, but the DART tree method controls the overall iterative process. In any algorithm with \"iteration\" as the core, we all face the same problem, that is, **the initial iteration greatly affects the direction of the entire algorithm, and subsequent iterations can only make minor repairs based on the previous ones**. This is intuitively easy to understand. After all, when we draw the curve of the loss function, we will find that the loss function drops sharply at the beginning of the iteration, but then gradually levels off. In this process, no over-fitting method can affect the process of those trees that are built first and have huge influence, but the DART tree can weaken the influence of these front-end trees and greatly improve the ability to resist over-fitting. ."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Parameter `rate_drop`: the proportion of trees dropped in each iteration\n",
    "> Set to 0.3, which means 30% of the trees will be dropped. It can only be used when the parameter `booster`=\"dart\" is used. Only floating point numbers between [0.0,1.0] can be filled in. The default value is 0.\n",
    "- Parameter `one_drop`: at least `one_drop` trees will be discarded in each iteration\n",
    "> Can be set to any positive integer, such as `one_drop` = 10, which means that at least 10 trees will be dropped in each iteration. <br><br>\n",
    "> When the value of parameter `one_drop` is higher than the result calculated in `rate_drop`, Dropout will be executed according to the setting in `one_drop`. For example, if there are 30 trees in total and `rate_drop` is set to 0.3, 9 trees need to be dropped. But if `one_drop` is set to 10, 10 trees will definitely be discarded. When the value of `one_drop` is lower than the calculation result of `rate_drop`, Dropout is executed according to the calculation result of `rate_drop`.\n",
    "- Parameter `skip_drop`: the probability that dropout will not be executed in each iteration\n",
    "> Even if the parameter `booster`='dart', there is a probability of `skip_drop` in each iteration without executing Dropout. It is the parameter with the highest authority among all set probability values. This parameter can only be filled with floating point numbers between [0.0,1.0], and the default value is 0. When this parameter is 0, it means that the tree will be discarded in each iteration. If this parameter is not 0, Dropout may not be executed and a new boosted tree will be directly established according to the rules of ordinary boosted trees. <br><br>\n",
    "> It should be noted that `skip_drop` has higher permissions than `one_drop`. Even if there is something set in `one_drop`, for example, at least 10 trees must be discarded in each iteration, as long as `skip_drop` is not 0, each iteration must pass the probability filter of `skip_drop`. If `skip_drop` says that Dropout will not be performed for this iteration, the settings in `one_drop` are ignored.\n",
    "- Parameter `sample_type`: the sampling method used when discarding\n",
    "> Fill in the string \"uniform\": means uniform sampling without replacement. <br><br>\n",
    "> Fill in the string \"weighted\": means to perform weighted sampling without replacement according to the weight of each tree. <br><br>\n",
    "> Note that no replacement means no replacement in one iteration. **The discards in each iteration are independent of each other, so each discard is discarded from all trees**. Trees that were discarded in the previous iteration may be included in the next iteration.\n",
    "- Parameter `normalize_type`: When adding a new tree, give the weight to the new tree\n",
    "> When the established trees are randomly discarded, the model results may be significantly offset. Therefore, subsequent trees often need to be given greater weight, making new and subsequent trees more important in the overall algorithm. . Therefore, when the DART tree builds a new tree, it will intentionally give subsequent trees greater weight. We have two options:<br><br>\n",
    "> Fill in the string \"tree\", indicating that the weight of the newly generated tree is equal to the average weight of all discarded trees. <br><br>\n",
    "> Fill in the string \"forest\", indicating that the weight of the newly generated tree is equal to the sum of the weights of all discarded trees.\n",
    "> The algorithm defaults to \"tree\". When our dropout ratio is large and we believe we want to give greater weight to subsequent trees, we will select \"forest\" mode.<br>\n",
    "> https://xgboost.readthedocs.io/en/stable/tutorials/dart.html"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When the model is prone to overfitting, we can try to use the DART tree to alleviate overfitting. However, DART trees will also bring corresponding problems. The most obvious disadvantages are:\n",
    "\n",
    "- Some trees used for fine-tuning the model may be discarded and fine-tuning may fail\n",
    "- Due to the presence of randomness, the model may become unstable, so features such as early stopping may become unstable as well\n",
    "- Since the results of some trees have to be randomly discarded, the $H_{k-1}$ calculated before each round cannot be used, and the selected tree results must be re-weighted and summed, which may cause the model iteration to become slightly slower."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import xgboost as xgb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\CODE\\Lib\\site-packages\\xgboost\\core.py:160: UserWarning: [15:46:32] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-0b3782d1791676daf-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:742: \n",
      "Parameters: { \"sample_tyer\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n"
     ]
    }
   ],
   "source": [
    "data_xgb = xgb.DMatrix(X, y)\n",
    "params_dart = {\"max_depth\":5, \"seed\":21,\"eta\":0.1,\n",
    "               \"booster\":\"dart\", \"sample_tyer\":\"uniform\",\n",
    "               \"rate_drop\": 0.2,\n",
    "               \"skip_drop\": 0.5}\n",
    "result_dart = xgb.cv(params_dart, data_xgb, num_boost_round=100,\n",
    "                     nfold=5,\n",
    "                     seed=21\n",
    "                     )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "train-rmse-mean     9774.380379\n",
       "train-rmse-std       114.828508\n",
       "test-rmse-mean     27210.582215\n",
       "test-rmse-std       3755.642758\n",
       "Name: 99, dtype: float64"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result_dart.iloc[-1,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "17436.20183590335"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result_dart.iloc[-1,2] - result_dart.iloc[-1,0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- ### **结构分数（Structure Score）与结构分数增益（Gain of Structure Score）**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "|类型|参数|\n",
    "|-|-|\n",
    "|**迭代过程/目标函数**|**params**: eta, base_score, objective, <font color=\"green\">**lambda, gamma, alpha, max_delta_step**</font><br>**xgb.train()**: num_boost_round|\n",
    "|**弱评估器结构**|**params**: max_depth, <font color=\"green\">**booster, min_child_weight**</font>|\n",
    "|**dart树**|**params**: <font color=\"green\">**sample_type, normalized_type, rate_drop, one_drop, skip_drop**</font>|\n",
    "|**弱评估器的训练数据**|**params**: subsample, <font color=\"green\">**sampling_method, colsamle_bytree, colsample_bylevel, colsample_bynode**</font>|\n",
    "|**提前停止**|**xgb.train()**: <font color=\"green\">**early_stopping_rounds, evals**</font>, eval_metric|\n",
    "|**其他**|**params**: seed, <font color=\"green\">**verbosity, scale_pos_weight, nthread**</font>|"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Assume that the objective function now uses L2 regularization and the parameter `gamma` that controls the number of leaves is 0. There is now a leaf node $j$, and the formula of the structure score for this node is:**\n",
    "\n",
    "$$ Score_j = \\frac{(\\sum_{i \\in j}g_i)^2}{\\sum_{i \\in j}h_i + \\lambda}$$\n",
    "\n",
    "Among them, $g_i$ is the first-order derivative of sample $i$ on the loss function $L$ to the predicted label, $h_i$ is the second-order derivative of sample $i$ on the loss function $L$ to the predicted label, $i \\in j$ means calculating all samples on leaf $j$, and $\\lambda$ is the regularization coefficient of L2 regularization. So it is not difficult to find that the structural score is actually:\n",
    "\n",
    "$$Score_j = \\frac{The square of the sum of the first-order derivatives of all samples on node j}{The sum of the second-order derivatives of all samples on node j + \\lambda}$$\n",
    "\n",
    "Note that structure scores are calculated for nodes, as are previously learned impurity measures such as Gini coefficient, information entropy, etc. On this basis, we rely on the structure score gain for branching. The structure score gain is expressed as:\n",
    "\n",
    "$$\\begin{align}\n",
    "Gain &= Score_L + Score_R - Score_P \\\\ \\\\\n",
    "&= \\frac{(\\sum_{i \\in L}g_i)^2}{\\sum_{i \\in L}h_i + \\lambda} + \\frac{(\\sum_{i \\in R}g_i)^2 }{\\sum_{i \\in R}h_i + \\lambda} - \\frac{(\\sum_{i \\in P}g_i)^2}{\\sum_{i \\in P}h_i + \\lambda}\\\\ \\ \\\n",
    "& (see formula No. 7 in the original paper)\n",
    "\\end{align}$$\n",
    "\n",
    "That is to say, the structural fractional gain is actually:\n",
    "\n",
    "$$Gain = structure score of left node + structure score of right node - structure score of parent node$$\n",
    "\n",
    "**We choose the point with the largest gain $Gain$ to branch**.\n",
    "\n",
    "Have you noticed that the branching rules in XGBoost are different in details from those of the classic CART tree? The information gain used in the CART tree is:\n",
    "\n",
    "$$Information gain in CART tree = Impurity of parent node - (Impurity of left node + Impurity of right node)$$\n",
    "\n",
    "What we are pursuing is the maximum information gain, which means that the overall impurity is gradually reduced as the CART tree is established. Regardless of whether the impurity measure is the Gini coefficient or information entropy, the smaller the impurity, the better. However, in XGBoost, the calculation formula of gain is opposite to that of CART tree, but we still pursue the maximum gain, so this means that with the establishment of XGBoost tree, the overall structure score gradually increases. Therefore we can think that the larger the structure score, the better."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "|样本|y|y_hat|\n",
    "|:-:|:-:|:-:|\n",
    "|1|1|0.5|\n",
    "|2|-2|0.5|\n",
    "|3|-2|0.5|\n",
    "- 分割方案1:（1,23）\n",
    "\n",
    "|左子节点|y|y_hat||右子节点|y|y_hat|\n",
    "|:-:|:-:|:-:|:-:|:-:|:-:|:-:|\n",
    "|1|1|0.5||2|-2|0.5|\n",
    "|||||3|-2|0.5|\n",
    "\n",
    "- 分割方案2:（12,3）\n",
    "\n",
    "|左子节点|y|y_hat||右子节点|y|y_hat|\n",
    "|:-:|:-:|:-:|:-:|:-:|:-:|:-:|\n",
    "|1|1|0.5||3|-2|0.5|\n",
    "|2|-2|0.5|||||\n",
    "\n",
    "假设现在执行的是XGBoost回归，损失函数为0.5倍MSE，公式为$\\frac{1}{2}(y - \\hat{y})^2$，假设lambda=1。那基于MSE的一阶导数为：\n",
    "\n",
    "$$\\begin{align}\n",
    "l&= \\frac{1}{2}(y_i - \\hat{y_i})^2 \\\\ \\\\ \n",
    "l' &= \\frac{\\partial}{\\partial \\hat{y_i}} \\frac{1}{2}(y_i - \\hat{y_i})^2\\\\ \\\\\n",
    "&= - (y_i - \\hat{y_i})\\\\ \\\\\n",
    "&= \\hat{y_i} - y_i\\\\ \\\\\n",
    "\\end{align}$$\n",
    "\n",
    "基于MSE的二阶导数为：\n",
    "\n",
    "$$\\begin{align}\n",
    "l'' &= \\frac{\\partial}{\\partial \\hat{y_i}} (\\hat{y_i} - y_i)\\\\ \\\\\n",
    "&= 1\n",
    "\\end{align}$$\n",
    "\n",
    "因此无论如何划分，$g_i = \\hat{y_i} - y_i$，$h_i = 1$。现在来计算父节点和两个子节点上每个样本的$g_i$与$h_i$："
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 父节点：\n",
    "\n",
    "|样本|y|y_hat|gi|hi|\n",
    "|:-:|:-:|:-:|:-:|:-:|\n",
    "|1|1|0.5|-0.5|1|\n",
    "|2|-2|0.5|2.5|1|\n",
    "|3|-2|0.5|2.5|1|\n",
    "\n",
    "因此父节点的结构分数为：\n",
    "\n",
    "$$\\begin{align}\n",
    "Score_P &= \\frac{(\\sum_{i \\in P}g_i)^2}{\\sum_{i \\in P}h_i + \\lambda} \\\\ \\\\\n",
    "&= \\frac{(-0.5 + 2.5 + 2.5)^2}{3 + 1} \\\\ \\\\\n",
    "&= 5.0625\n",
    "\\end{align}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 方案1\n",
    "\n",
    "|左子节点|y|y_hat|gi|hi||右子节点|y|y_hat|gi|hi|\n",
    "|:-:|:-:|:-:|:-:|:-:|:-:|:-:|:-:|:-:|:-:|:-:|\n",
    "|1|1|0.5|-0.5|1||2|-2|0.5|2.5|1|\n",
    "|||||||3|-2|0.5|2.5|1|\n",
    "\n",
    "方案1下两个子节点的结构分数为：\n",
    "\n",
    "$$\\begin{align}\n",
    "Score_{L1} &= \\frac{(\\sum_{i \\in {L1}}g_i)^2}{\\sum_{i \\in {L1}}h_i + \\lambda} \\\\ \\\\\n",
    "&= \\frac{(-0.5)^2}{1 + 1} \\\\ \\\\\n",
    "&= 0.125\n",
    "\\end{align}$$\n",
    "\n",
    "<br>\n",
    "\n",
    "$$\\begin{align}\n",
    "Score_{R1} &= \\frac{(\\sum_{i \\in {R1}}g_i)^2}{\\sum_{i \\in {R1}}h_i + \\lambda} \\\\ \\\\\n",
    "&= \\frac{(2.5+2.5)^2}{2 + 1} \\\\ \\\\\n",
    "&= 8.333\n",
    "\\end{align}$$\n",
    "\n",
    "因此增益等于：\n",
    "\n",
    "$$\\begin{align}\n",
    "Gain &= Score_{L1} + Score_{R1} - Score_P \\\\ \\\\\n",
    "&= 0.125 + 8.333 - 5.6025 \\\\ \\\\\n",
    "&= 3.395\n",
    "\\end{align}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 方案2\n",
    "\n",
    "|左子节点|y|y_hat|gi|hi||右子节点|y|y_hat|gi|hi|\n",
    "|:-:|:-:|:-:|:-:|:-:|:-:|:-:|:-:|:-:|:-:|:-:|\n",
    "|1|1|0.5|-0.5|1||3|-2|0.5|2.5|1|\n",
    "|2|-2|0.5|2.5|1|||||||\n",
    "\n",
    "方案1下两个子节点的结构分数为：\n",
    "\n",
    "$$\\begin{align}\n",
    "Score_{L1} &= \\frac{(\\sum_{i \\in {L1}}g_i)^2}{\\sum_{i \\in {L1}}h_i + \\lambda} \\\\ \\\\\n",
    "&= \\frac{(-0.5 + 2.5)^2}{2 + 1} \\\\ \\\\\n",
    "&= 1.333\n",
    "\\end{align}$$\n",
    "\n",
    "<br>\n",
    "\n",
    "$$\\begin{align}\n",
    "Score_{R1} &= \\frac{(\\sum_{i \\in {R1}}g_i)^2}{\\sum_{i \\in {R1}}h_i + \\lambda} \\\\ \\\\\n",
    "&= \\frac{(2.5)^2}{1 + 1} \\\\ \\\\\n",
    "&= 3.125\n",
    "\\end{align}$$\n",
    "\n",
    "因此增益等于：\n",
    "\n",
    "$$\\begin{align}\n",
    "Gain &= Score_{L1} + Score_{R1} - Score_P \\\\ \\\\\n",
    "&= 1.333 + 3.125 - 5.0625 \\\\ \\\\ \n",
    "&= -0.604\n",
    "\\end{align}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "|方案|左侧结构分数|右侧结构分数|父节点结构分数|增益|\n",
    "|:-:|:-:|:-:|:-:|:-:|\n",
    "|**(1,23)**|0.125|8.333|5.0625|<font color=\"green\">**3.3958**</font>|\n",
    "|**(12,3)**|1.333|3.125|5.0625|-0.6041|"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**We use the sum of the structure scores of all leaves on a tree to evaluate the structure of the entire tree**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Control complexity : pruning of weak esitmator"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Parameter `min_child_weight`: can be broadly understood as the sample size (sample weight) allowed on any node.\n",
    "> To put it more strictly, `min_child_weight` is the smallest $\\sum_{i \\in j}h_i$ value allowed on any node $j$. If $\\sum_{i \\in j}h_i$ on a node is less than the value set in this parameter, the node is pruned. <br><br>\n",
    "> If you study the previous section carefully, you will easily understand that $\\sum_{i \\in j}h_i$ is actually the denominator of the structural fraction:\n",
    "> $$ Score_j = \\frac{(\\sum_{i \\in j}g_i)^2}{\\sum_{i \\in j}h_i + \\lambda}$$\n",
    "> Among them, $h_i$ is the second derivative of the loss function $l$ of sample $i$ on the predicted value $f(x_i)$, and $\\sum_{i \\in j}h_i$ is the value of all samples on the node The sum of $h_i$. <br><br>\n",
    "> In the previous section, assuming the loss function is $\\frac{1}{2}MSE$, we derived $h_i = 1$ for any sample, so $\\sum_{i \\in j}h_i$ should be equal to The total sample size on leaf nodes. For this reason, $h_i$ is sometimes called \"instance weight\" in the original XGBoost paper and official description. Therefore, when MSE is the loss function, the parameter `min_child_weight` is very similar to `min_sample_leaf` in sklearn, which is the minimum sample size allowed on a node. <br><br>\n",
    "> However, if the loss function we use is not MSE, then $h_i$ will not be equal to 1. However, the official still calls $h_i$ the sample weight. When the loss function is changed, the weight of the sample also changes accordingly. When the loss function is not MSE, the parameter `min_child_weight` is the minimum sample weight allowed on a node. <br><br>\n",
    "> Obviously, the larger the parameter `min_child_weight`, the less likely the model is to overfit, and the weaker the learning ability."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 参数`gamma`：目标函数中叶子数量$T$前的系数，同时也是允许分枝的最低结构分数增益。当分枝时结构增益不足`gamma`中设置的值，该节点被剪枝。\n",
    "> 在目标函数当中，`gamma`是叶子数量$T$前的系数，放大gamma可以将目标函数的重点转移至结构风险，从而控制过拟合：<br><br>\n",
    "> $$Obj_k = \\sum_{i=1}^Ml(y_i,\\hat{y_i}) + \\boldsymbol{\\color{red}\\gamma} T + \\frac{1}{2}\\boldsymbol{\\color{red}\\lambda}\\sum_{j=1}^Tw_j^2 + \\boldsymbol{\\color{red}\\alpha}\\sum_{j=1}^Tw_j$$ \n",
    "> 在上一节中介绍结构分数时，我们曾做出假设`gamma`为0，当`gamma`不为0时，结构分数增益的公式如下：<br><br>\n",
    "> $$\\begin{align}\n",
    "Gain &= \\frac{1}{2} ( Score_L + Score_R - Score_P ) - \\gamma \\\\ \\\\\n",
    "&= \\frac{1}{2} \\left( \\frac{(\\sum_{i \\in L}g_i)^2}{\\sum_{i \\in L}h_i + \\lambda} + \\frac{(\\sum_{i \\in R}g_i)^2}{\\sum_{i \\in R}h_i + \\lambda} - \\frac{(\\sum_{i \\in P}g_i)^2}{\\sum_{i \\in P}h_i + \\lambda} \\right) - \\gamma\n",
    "\\end{align}$$ \n",
    "> 在XGBoost中，我们追求一棵树整体的结构分数最大，因此XGBoost规定**任意结构的分数增益不能为负，任意增益为负的节点都会被剪枝**，因此可以默认有：\n",
    "> $$\\frac{1}{2} \\left( \\frac{(\\sum_{i \\in L}g_i)^2}{\\sum_{i \\in L}h_i + \\lambda} + \\frac{(\\sum_{i \\in R}g_i)^2}{\\sum_{i \\in R}h_i + \\lambda} - \\frac{(\\sum_{i \\in P}g_i)^2}{\\sum_{i \\in P}h_i + \\lambda} \\right) - \\gamma > 0$$\n",
    "> 因此：\n",
    "> $$\\frac{1}{2} \\left( \\frac{(\\sum_{i \\in L}g_i)^2}{\\sum_{i \\in L}h_i + \\lambda} + \\frac{(\\sum_{i \\in R}g_i)^2}{\\sum_{i \\in R}h_i + \\lambda} - \\frac{(\\sum_{i \\in P}g_i)^2}{\\sum_{i \\in P}h_i + \\lambda} \\right) > \\gamma\n",
    "$$\n",
    "> 这是说，当参数`gamma`为0时，任意增益为负的节点都会被剪枝。当`gamma`为任意正数时，任意增益小于`gamma`设定值的节点都会被剪枝。不难发现，`gamma`在剪枝中的作用就相当于sklearn中的`min_impurity_decrease`。<br><br>\n",
    "> 很显然，`gamma`值越大，算法越不容易过拟合，同时学习能力也越弱。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 参数`lambda`和`alpha`：正则化系数，同时也位于结构分数中间接影响树的生长和分枝。\n",
    "> 当使用L2正则化时，结构分数为：\n",
    "> $$ Score_j = \\frac{(\\sum_{i \\in j}g_i)^2}{\\sum_{i \\in j}h_i + \\lambda}$$\n",
    "> 然而，当使用L1正则化时，结构分数为：\n",
    "> $$ Score_j = \\frac{(\\sum_{i \\in j}g_i)^2 + \\alpha}{\\sum_{i \\in j}h_i}$$\n",
    "> 因此，当`lambda`越大，结构分数会越小，参数`gamma`的力量会被放大，模型整体的剪枝会变得更加严格，同时，由于`lambda`还可以通过目标函数将模型学习的重点拉向结构风险，因此`lambda`具有双重扛过拟合能力。<br><br>\n",
    "> 然而，当`alpha`越大时，结构分数会越大，参数`gamma`的力量会被缩小，模型整体的剪枝会变得更宽松。然而，`alpha`还可以通过目标函数将模型学习的重点拉向结构风险，因此`alpha`会通过放大结构分数抵消一部分扛过拟合的能力。整体来看，`alpha`是比`lambda`更宽松的剪枝方式。<br><br>\n",
    "> 在XGBoost当中，我们可以同时使用两种正则化，则结构分数为：<br><br>\n",
    "> $$ Score_j = \\frac{(\\sum_{i \\in j}g_i)^2 + \\alpha}{\\sum_{i \\in j}h_i + \\lambda}$$\n",
    "> 此时，影响模型变化的因子会变得过多，我们难以再从中找到规律，调参会因此变得略有困难。但是当你感觉到L2正则化本身不足以抵抗过拟合的时候，可以使用L1+L2正则化的方式尝试调参。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Control complexity: training data for weak evaluators"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In addition to controlling model complexity through pruning, XGBoost also inherits the fine traditions of GBDT and random forests: it can increase the diversity of weak evaluators by sampling samples and features to control overfitting. The parameters used in this part are all those we have seen before, but in XGBoost, we can perform richer data sampling:\n",
    "\n",
    "**Sampling**\n",
    "\n",
    "- Parameter `subsample`: the proportion of sampling samples, the default is 1, you can enter any floating point number between (0,1]. For example, entering 0.5 means randomly sampling 50% of the samples to build the tree.\n",
    "> When this parameter is set to 1, it means using original data for modeling without sampling. At the same time, the sample sampling in **XGBoost is sampling without replacement**, so it does not have the problem of out-of-bag data like GBDT or random forest, and it is also unable to sample more samples than the original data. Therefore, the sample size can only remain the same or become smaller after sampling. If the sample size is small, it is recommended to keep `subsample`=1.\n",
    "- Parameter `sampling_method`: The sampling method used when sampling samples, the default is uniform sampling.\n",
    "> Enter \"uniform\": Indicates that uniform sampling is used, and each sample has the same probability of being drawn. If uniform sampling is used, it is recommended that the ratio of `subsample` be 0.5 or above. <br><br>\n",
    "> It should be noted that this parameter also contains another possible input \"gradient_based\": indicating that weighted sampling is used, and the weight of each sample is equal to $\\sqrt{g_i^2 +\\lambda h_i^2 of the sample }$. However, this input currently does not support the mainstream tree-building methods such as gbtree in XGBoost, so generally we will not use it."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Sampling of features**\n",
    "\n",
    "- Parameters `colsample_bytree`, `colsample_bylevel`, `colsample_bynode`, these parameters communicate with each other to control the sampling of features.\n",
    "> All parameters similar to `colsample_by*` are sampling ratios. You can enter any floating point number between (0,1], and the default value is 1.<br><br>\n",
    "> For GBDT and random forest, feature sampling occurs before each tree building. But for XGBoost, feature sampling can occur before building a tree (controlled by `colsample_bytree`), before growing a new layer of tree (controlled by `colsample_bylevel`), or before each node branches (controlled by `colsample_bynode` control). <br><br>\n",
    "> The three parameters will affect each other, **Full feature set>= Feature subset used to build the tree>= Feature subset used to build each layer>= Feature subset used when each node branches** . <br><br>\n",
    "> For example: Suppose there are originally 64 features and the parameter `colsample_bytree` is equal to 0.5, then there are only 32 features used to build the tree. At this time, if `colsample_bylevel` is not 1, but also 0.5, then the features used in the new layer can only be 16, and **these 16 features can only be selected from the 32 features that have been sampled by the current tree**. Similarly, if `colsample_bynode` is not 1 but 0.5, then there are only 8 features used before each branch, and these 8 features can only be selected from the 16 features that have been sampled in the current layer. <br><br>\n",
    "> In actual use, we can set the ratio of any sampling parameter to 1, and no sampling can be performed in a certain link. Generally, if the number of features is too small (for example, less than 10), it is not recommended to use three parameters at the same time."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "|类型|参数|\n",
    "|---|---|\n",
    "|**弱评估器**|<font color=\"green\">**booster**</font>：选择迭代过程中的弱评估器类型，包括gbtree，DART和线性模型<br><br><font color=\"green\">**sample_type**</font>：DART树中随机抽样树的具体方法<br><br><font color=\"green\">**rate_drop**</font>：DART树中所使用的抛弃率<br><br><font color=\"green\">**one_drop**</font>：每轮迭代时至少需要抛弃的树的数量<br><br><font color=\"green\">**skip_drop**</font>：在迭代中不进行抛弃的概率<br><br><font color=\"green\">**normalized_type**</font>：根据被抛弃的树的权重控制新增树权重<br><br>max_depth：允许的弱评估器的最大深度<br><br><font color=\"green\">**min_child_weight**：</font>（广义上）叶子节点上的最小样本权重/最小样本量<br><br><font color=\"green\">**gamma**</font>：目标函数中叶子数量$T$的系数，同时也是分枝时所需的最小结构分数增益值<br><br><font color=\"green\">**lambda**与**alpha**</font>：正则项系数，同时也位于结构分数的公式中，间接影响模型的剪枝<br><br><font color=\"green\">**sample_type**</font>：对样本进行抽样具体方式<br><br><font color=\"green\">**subsample**</font>：对样本进行抽样的具体比例<br><br><font color=\"green\">**colsample_bytree, colsample_bylevel, colsample_bynode**</font>：在建树过程中对特征进行抽样的比例|\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "|类型|参数|\n",
    "|-|-|\n",
    "|**迭代过程/目标函数**|**params**: eta, base_score, objective, <font color=\"green\">**lambda, gamma, alpha, max_delta_step**</font><br>**xgb.train()**: num_boost_round|\n",
    "|**弱评估器结构**|**params**: max_depth, <font color=\"green\">**booster, min_child_weight**</font>|\n",
    "|**dart树**|**params**: <font color=\"green\">**sample_type, normalized_type, rate_drop, one_drop, skip_drop**</font>|\n",
    "|**弱评估器的训练数据**|**params**: subsample, <font color=\"green\">**sampling_method, colsamle_bytree, colsample_bylevel, colsample_bynode**</font>|\n",
    "|**提前停止**|**xgb.train()**: <font color=\"green\">**early_stopping_rounds, evals**</font>, eval_metric|\n",
    "|**其他**|**params**: seed, <font color=\"green\">**verbosity, scale_pos_weight, nthread**</font>|"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### XGBoost hyperparameters optimazation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "|影响力|参数|\n",
    "|:-:|:-:|\n",
    "|⭐⭐⭐⭐⭐<br>几乎总是具有巨大影响力|num_boost_round（整体学习能力）<br>eta（整体学习速率）<br>|\n",
    "|⭐⭐⭐⭐<br>大部分时候具有影响力|booster（整体学习能力）<br>colsample_by*（随机性）<br>gamma（结构风险 + 精剪枝）<br>lambda（结构风险 + 间接剪枝）<br> min_child_weight（精剪枝）|\n",
    "|⭐⭐<br>可能有大影响力<br>大部分时候影响力不明显|max_depth（粗剪枝）<br>alpha（结构风险 + 精剪枝）<br>subsamples（随机性）<br>objective（整体学习能力）<br>scale_pos_weight（样本不均衡）|\n",
    "|⭐<br>当数据量足够大时，几乎无影响|seed<br>base_score（初始化）<br>|"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "#日常使用库与算法\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import sklearn\n",
    "import matplotlib as mlp\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "import xgboost as xgb\n",
    "\n",
    "#导入优化算法\n",
    "import hyperopt\n",
    "from hyperopt import hp, fmin, tpe, Trials, partial\n",
    "from hyperopt.early_stop import no_progress_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv(r\"D:\\Practice\\Machine Learning\\datasets\\House Price\\train_encode.csv\",index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = data.iloc[:,:-1]\n",
    "y = data.iloc[:,-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def hyperopt_objective(params):\n",
    "    paramsforxgb = {\"eta\":params[\"eta\"]\n",
    "                    ,\"booster\":params[\"booster\"]\n",
    "                    ,\"colsample_bytree\":params[\"colsample_bytree\"]\n",
    "                    ,\"colsample_bynode\":params[\"colsample_bynode\"]\n",
    "                    ,\"gamma\":params[\"gamma\"]\n",
    "                    ,\"lambda\":params[\"lambda\"]\n",
    "                    ,\"min_child_weight\":params[\"min_child_weight\"]\n",
    "                    ,\"max_depth\":int(params[\"max_depth\"])\n",
    "                    ,\"subsample\":params[\"subsample\"]\n",
    "                    ,\"objective\":params[\"objective\"]\n",
    "                    ,\"rate_drop\":params[\"rate_drop\"]\n",
    "                    ,\"nthread\":14\n",
    "                    ,\"verbosity\":0\n",
    "                    ,\"seed\":1412}\n",
    "    result = xgb.cv(params,data_xgb, seed=1412, metrics=(\"rmse\")\n",
    "                    ,num_boost_round=int(params[\"num_boost_round\"]))\n",
    "    return result.iloc[-1,2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_grid_simple = {'num_boost_round': hp.quniform(\"num_boost_round\",50,200,10)\n",
    "                     ,\"eta\": hp.quniform(\"eta\",0.05,2.05,0.05)\n",
    "                     ,\"booster\":hp.choice(\"booster\",[\"gbtree\",\"dart\"])\n",
    "                     ,\"colsample_bytree\":hp.quniform(\"colsample_bytree\",0.3,1,0.1)\n",
    "                     ,\"colsample_bynode\":hp.quniform(\"colsample_bynode\",0.1,1,0.1)\n",
    "                     ,\"gamma\":hp.quniform(\"gamma\",1e6,1e7,1e6)\n",
    "                     ,\"lambda\":hp.quniform(\"lambda\",0,3,0.2)\n",
    "                     ,\"min_child_weight\":hp.quniform(\"min_child_weight\",0,50,2)\n",
    "                     ,\"max_depth\":hp.choice(\"max_depth\",[*range(2,30,2)])\n",
    "                     ,\"subsample\":hp.quniform(\"subsample\",0.1,1,0.1)\n",
    "                     ,\"objective\":hp.choice(\"objective\",[\"reg:squarederror\",\"reg:squaredlogerror\"])\n",
    "                     ,\"rate_drop\":hp.quniform(\"rate_drop\",0.1,1,0.1)\n",
    "                    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def param_hyperopt(max_evals=100):\n",
    "    \n",
    "    #保存迭代过程\n",
    "    trials = Trials()\n",
    "    \n",
    "    #设置提前停止\n",
    "    early_stop_fn = no_progress_loss(30)\n",
    "    \n",
    "    #定义代理模型\n",
    "    params_best = fmin(hyperopt_objective\n",
    "                       , space = param_grid_simple\n",
    "                       , algo = tpe.suggest\n",
    "                       , max_evals = max_evals\n",
    "                       , verbose=True\n",
    "                       , trials = trials\n",
    "                       , early_stop_fn = early_stop_fn\n",
    "                      )\n",
    "    \n",
    "    #打印最优参数，fmin会自动打印最佳分数\n",
    "    print(\"\\n\",\"\\n\",\"best params: \", params_best,\n",
    "          \"\\n\")\n",
    "    return params_best, trials"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/100 [00:00<?, ?trial/s, best loss=?]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\CODE\\Lib\\site-packages\\xgboost\\core.py:160: UserWarning: [16:34:40] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-0b3782d1791676daf-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:742: \n",
      "Parameters: { \"num_boost_round\", \"rate_drop\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  1%|          | 1/100 [00:01<02:29,  1.51s/trial, best loss: 197550.31040883122]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\CODE\\Lib\\site-packages\\xgboost\\core.py:160: UserWarning: [16:34:42] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-0b3782d1791676daf-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:742: \n",
      "Parameters: { \"num_boost_round\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  2%|▏         | 2/100 [00:12<11:40,  7.15s/trial, best loss: 38004.3889090004]  "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\CODE\\Lib\\site-packages\\xgboost\\core.py:160: UserWarning: [16:34:53] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-0b3782d1791676daf-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:742: \n",
      "Parameters: { \"num_boost_round\", \"rate_drop\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  3%|▎         | 3/100 [00:13<07:01,  4.34s/trial, best loss: 32055.126211356834]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\CODE\\Lib\\site-packages\\xgboost\\core.py:160: UserWarning: [16:34:54] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-0b3782d1791676daf-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:742: \n",
      "Parameters: { \"num_boost_round\", \"rate_drop\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  4%|▍         | 4/100 [00:14<04:43,  2.95s/trial, best loss: 32055.126211356834]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\CODE\\Lib\\site-packages\\xgboost\\core.py:160: UserWarning: [16:34:55] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-0b3782d1791676daf-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:742: \n",
      "Parameters: { \"num_boost_round\", \"rate_drop\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  5%|▌         | 5/100 [00:16<04:08,  2.62s/trial, best loss: 32055.126211356834]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\CODE\\Lib\\site-packages\\xgboost\\core.py:160: UserWarning: [16:34:57] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-0b3782d1791676daf-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:742: \n",
      "Parameters: { \"num_boost_round\", \"rate_drop\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  6%|▌         | 6/100 [00:17<03:05,  1.98s/trial, best loss: 32055.126211356834]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\CODE\\Lib\\site-packages\\xgboost\\core.py:160: UserWarning: [16:34:57] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-0b3782d1791676daf-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:742: \n",
      "Parameters: { \"num_boost_round\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  7%|▋         | 7/100 [00:22<04:47,  3.09s/trial, best loss: 32055.126211356834]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\CODE\\Lib\\site-packages\\xgboost\\core.py:160: UserWarning: [16:35:03] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-0b3782d1791676daf-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:742: \n",
      "Parameters: { \"num_boost_round\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  8%|▊         | 8/100 [00:26<04:54,  3.20s/trial, best loss: 32055.126211356834]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\CODE\\Lib\\site-packages\\xgboost\\core.py:160: UserWarning: [16:35:06] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-0b3782d1791676daf-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:742: \n",
      "Parameters: { \"num_boost_round\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  9%|▉         | 9/100 [00:30<05:32,  3.65s/trial, best loss: 32055.126211356834]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\CODE\\Lib\\site-packages\\xgboost\\core.py:160: UserWarning: [16:35:11] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-0b3782d1791676daf-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:742: \n",
      "Parameters: { \"num_boost_round\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 10%|█         | 10/100 [00:37<07:03,  4.70s/trial, best loss: 32055.126211356834]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\CODE\\Lib\\site-packages\\xgboost\\core.py:160: UserWarning: [16:35:18] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-0b3782d1791676daf-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:742: \n",
      "Parameters: { \"num_boost_round\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 11%|█         | 11/100 [00:47<09:20,  6.29s/trial, best loss: 32055.126211356834]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\CODE\\Lib\\site-packages\\xgboost\\core.py:160: UserWarning: [16:35:28] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-0b3782d1791676daf-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:742: \n",
      "Parameters: { \"num_boost_round\", \"rate_drop\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 12%|█▏        | 12/100 [00:48<06:52,  4.69s/trial, best loss: 32055.126211356834]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\CODE\\Lib\\site-packages\\xgboost\\core.py:160: UserWarning: [16:35:29] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-0b3782d1791676daf-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:742: \n",
      "Parameters: { \"num_boost_round\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 13%|█▎        | 13/100 [00:55<07:36,  5.25s/trial, best loss: 32055.126211356834]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\CODE\\Lib\\site-packages\\xgboost\\core.py:160: UserWarning: [16:35:35] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-0b3782d1791676daf-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:742: \n",
      "Parameters: { \"num_boost_round\", \"rate_drop\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 14%|█▍        | 14/100 [00:55<05:32,  3.87s/trial, best loss: 32055.126211356834]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\CODE\\Lib\\site-packages\\xgboost\\core.py:160: UserWarning: [16:35:36] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-0b3782d1791676daf-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:742: \n",
      "Parameters: { \"num_boost_round\", \"rate_drop\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 15%|█▌        | 15/100 [00:57<04:38,  3.28s/trial, best loss: 32055.126211356834]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\CODE\\Lib\\site-packages\\xgboost\\core.py:160: UserWarning: [16:35:38] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-0b3782d1791676daf-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:742: \n",
      "Parameters: { \"num_boost_round\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 16%|█▌        | 16/100 [01:00<04:17,  3.07s/trial, best loss: 32055.126211356834]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\CODE\\Lib\\site-packages\\xgboost\\core.py:160: UserWarning: [16:35:41] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-0b3782d1791676daf-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:742: \n",
      "Parameters: { \"num_boost_round\", \"rate_drop\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 17%|█▋        | 17/100 [01:01<03:38,  2.63s/trial, best loss: 32055.126211356834]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\CODE\\Lib\\site-packages\\xgboost\\core.py:160: UserWarning: [16:35:42] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-0b3782d1791676daf-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:742: \n",
      "Parameters: { \"num_boost_round\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 18%|█▊        | 18/100 [01:15<07:54,  5.79s/trial, best loss: 29152.65823974111] "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\CODE\\Lib\\site-packages\\xgboost\\core.py:160: UserWarning: [16:35:55] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-0b3782d1791676daf-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:742: \n",
      "Parameters: { \"num_boost_round\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 19%|█▉        | 19/100 [01:23<08:50,  6.55s/trial, best loss: 29152.65823974111]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\CODE\\Lib\\site-packages\\xgboost\\core.py:160: UserWarning: [16:36:04] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-0b3782d1791676daf-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:742: \n",
      "Parameters: { \"num_boost_round\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 20%|██        | 20/100 [01:28<08:03,  6.05s/trial, best loss: 29152.65823974111]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\CODE\\Lib\\site-packages\\xgboost\\core.py:160: UserWarning: [16:36:09] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-0b3782d1791676daf-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:742: \n",
      "Parameters: { \"num_boost_round\", \"rate_drop\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 22%|██▏       | 22/100 [01:29<04:17,  3.30s/trial, best loss: 29152.65823974111]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\CODE\\Lib\\site-packages\\xgboost\\core.py:160: UserWarning: [16:36:10] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-0b3782d1791676daf-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:742: \n",
      "Parameters: { \"num_boost_round\", \"rate_drop\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 23%|██▎       | 23/100 [01:31<03:38,  2.84s/trial, best loss: 29152.65823974111]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\CODE\\Lib\\site-packages\\xgboost\\core.py:160: UserWarning: [16:36:12] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-0b3782d1791676daf-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:742: \n",
      "Parameters: { \"num_boost_round\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 24%|██▍       | 24/100 [01:33<03:22,  2.66s/trial, best loss: 29152.65823974111]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\CODE\\Lib\\site-packages\\xgboost\\core.py:160: UserWarning: [16:36:14] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-0b3782d1791676daf-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:742: \n",
      "Parameters: { \"num_boost_round\", \"rate_drop\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 25%|██▌       | 25/100 [01:34<02:46,  2.22s/trial, best loss: 29152.65823974111]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\CODE\\Lib\\site-packages\\xgboost\\core.py:160: UserWarning: [16:36:15] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-0b3782d1791676daf-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:742: \n",
      "Parameters: { \"num_boost_round\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 26%|██▌       | 26/100 [01:41<04:18,  3.49s/trial, best loss: 29152.65823974111]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\CODE\\Lib\\site-packages\\xgboost\\core.py:160: UserWarning: [16:36:22] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-0b3782d1791676daf-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:742: \n",
      "Parameters: { \"num_boost_round\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 27%|██▋       | 27/100 [01:46<04:44,  3.89s/trial, best loss: 29152.65823974111]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\CODE\\Lib\\site-packages\\xgboost\\core.py:160: UserWarning: [16:36:26] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-0b3782d1791676daf-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:742: \n",
      "Parameters: { \"num_boost_round\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 28%|██▊       | 28/100 [01:55<06:33,  5.46s/trial, best loss: 29152.65823974111]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\CODE\\Lib\\site-packages\\xgboost\\core.py:160: UserWarning: [16:36:36] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-0b3782d1791676daf-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:742: \n",
      "Parameters: { \"num_boost_round\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 29%|██▉       | 29/100 [02:08<09:17,  7.86s/trial, best loss: 29152.65823974111]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\CODE\\Lib\\site-packages\\xgboost\\core.py:160: UserWarning: [16:36:49] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-0b3782d1791676daf-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:742: \n",
      "Parameters: { \"num_boost_round\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 30%|███       | 30/100 [02:21<10:55,  9.37s/trial, best loss: 28813.924594627646]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\CODE\\Lib\\site-packages\\xgboost\\core.py:160: UserWarning: [16:37:02] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-0b3782d1791676daf-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:742: \n",
      "Parameters: { \"num_boost_round\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 31%|███       | 31/100 [02:33<11:47, 10.25s/trial, best loss: 28813.924594627646]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\CODE\\Lib\\site-packages\\xgboost\\core.py:160: UserWarning: [16:37:14] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-0b3782d1791676daf-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:742: \n",
      "Parameters: { \"num_boost_round\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 32%|███▏      | 32/100 [02:49<13:26, 11.86s/trial, best loss: 28813.924594627646]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\CODE\\Lib\\site-packages\\xgboost\\core.py:160: UserWarning: [16:37:30] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-0b3782d1791676daf-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:742: \n",
      "Parameters: { \"num_boost_round\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 33%|███▎      | 33/100 [03:05<14:34, 13.05s/trial, best loss: 28813.924594627646]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\CODE\\Lib\\site-packages\\xgboost\\core.py:160: UserWarning: [16:37:46] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-0b3782d1791676daf-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:742: \n",
      "Parameters: { \"num_boost_round\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 34%|███▍      | 34/100 [03:17<14:11, 12.90s/trial, best loss: 28813.924594627646]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\CODE\\Lib\\site-packages\\xgboost\\core.py:160: UserWarning: [16:37:58] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-0b3782d1791676daf-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:742: \n",
      "Parameters: { \"num_boost_round\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 35%|███▌      | 35/100 [03:31<14:03, 12.98s/trial, best loss: 28813.924594627646]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\CODE\\Lib\\site-packages\\xgboost\\core.py:160: UserWarning: [16:38:11] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-0b3782d1791676daf-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:742: \n",
      "Parameters: { \"num_boost_round\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 36%|███▌      | 36/100 [03:40<12:41, 11.90s/trial, best loss: 28813.924594627646]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\CODE\\Lib\\site-packages\\xgboost\\core.py:160: UserWarning: [16:38:21] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-0b3782d1791676daf-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:742: \n",
      "Parameters: { \"num_boost_round\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 37%|███▋      | 37/100 [03:54<13:15, 12.63s/trial, best loss: 28813.924594627646]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\CODE\\Lib\\site-packages\\xgboost\\core.py:160: UserWarning: [16:38:35] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-0b3782d1791676daf-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:742: \n",
      "Parameters: { \"num_boost_round\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 38%|███▊      | 38/100 [04:02<11:28, 11.10s/trial, best loss: 28813.924594627646]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\CODE\\Lib\\site-packages\\xgboost\\core.py:160: UserWarning: [16:38:43] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-0b3782d1791676daf-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:742: \n",
      "Parameters: { \"num_boost_round\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 39%|███▉      | 39/100 [04:16<12:19, 12.13s/trial, best loss: 28813.924594627646]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\CODE\\Lib\\site-packages\\xgboost\\core.py:160: UserWarning: [16:38:57] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-0b3782d1791676daf-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:742: \n",
      "Parameters: { \"num_boost_round\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 40%|████      | 40/100 [04:30<12:26, 12.44s/trial, best loss: 28813.924594627646]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\CODE\\Lib\\site-packages\\xgboost\\core.py:160: UserWarning: [16:39:10] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-0b3782d1791676daf-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:742: \n",
      "Parameters: { \"num_boost_round\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 41%|████      | 41/100 [04:45<13:01, 13.25s/trial, best loss: 28780.701695406886]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\CODE\\Lib\\site-packages\\xgboost\\core.py:160: UserWarning: [16:39:25] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-0b3782d1791676daf-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:742: \n",
      "Parameters: { \"num_boost_round\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 42%|████▏     | 42/100 [04:50<10:39, 11.02s/trial, best loss: 28780.701695406886]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\CODE\\Lib\\site-packages\\xgboost\\core.py:160: UserWarning: [16:39:31] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-0b3782d1791676daf-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:742: \n",
      "Parameters: { \"num_boost_round\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 43%|████▎     | 43/100 [04:55<08:39,  9.11s/trial, best loss: 28780.701695406886]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\CODE\\Lib\\site-packages\\xgboost\\core.py:160: UserWarning: [16:39:36] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-0b3782d1791676daf-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:742: \n",
      "Parameters: { \"num_boost_round\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 44%|████▍     | 44/100 [05:04<08:30,  9.12s/trial, best loss: 28780.701695406886]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\CODE\\Lib\\site-packages\\xgboost\\core.py:160: UserWarning: [16:39:45] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-0b3782d1791676daf-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:742: \n",
      "Parameters: { \"num_boost_round\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 45%|████▌     | 45/100 [05:18<09:34, 10.44s/trial, best loss: 28780.701695406886]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\CODE\\Lib\\site-packages\\xgboost\\core.py:160: UserWarning: [16:39:59] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-0b3782d1791676daf-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:742: \n",
      "Parameters: { \"num_boost_round\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 46%|████▌     | 46/100 [05:27<09:02, 10.05s/trial, best loss: 28780.701695406886]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\CODE\\Lib\\site-packages\\xgboost\\core.py:160: UserWarning: [16:40:08] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-0b3782d1791676daf-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:742: \n",
      "Parameters: { \"num_boost_round\", \"rate_drop\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 47%|████▋     | 47/100 [05:29<06:44,  7.63s/trial, best loss: 28780.701695406886]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\CODE\\Lib\\site-packages\\xgboost\\core.py:160: UserWarning: [16:40:10] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-0b3782d1791676daf-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:742: \n",
      "Parameters: { \"num_boost_round\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 48%|████▊     | 48/100 [05:33<05:48,  6.70s/trial, best loss: 28780.701695406886]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\CODE\\Lib\\site-packages\\xgboost\\core.py:160: UserWarning: [16:40:14] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-0b3782d1791676daf-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:742: \n",
      "Parameters: { \"num_boost_round\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 49%|████▉     | 49/100 [05:43<06:31,  7.67s/trial, best loss: 28780.701695406886]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\CODE\\Lib\\site-packages\\xgboost\\core.py:160: UserWarning: [16:40:24] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-0b3782d1791676daf-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:742: \n",
      "Parameters: { \"num_boost_round\", \"rate_drop\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 50%|█████     | 50/100 [05:45<04:48,  5.77s/trial, best loss: 28780.701695406886]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\CODE\\Lib\\site-packages\\xgboost\\core.py:160: UserWarning: [16:40:26] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-0b3782d1791676daf-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:742: \n",
      "Parameters: { \"num_boost_round\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 51%|█████     | 51/100 [05:51<04:46,  5.84s/trial, best loss: 28780.701695406886]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\CODE\\Lib\\site-packages\\xgboost\\core.py:160: UserWarning: [16:40:32] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-0b3782d1791676daf-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:742: \n",
      "Parameters: { \"num_boost_round\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 52%|█████▏    | 52/100 [05:59<05:14,  6.56s/trial, best loss: 28780.701695406886]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\CODE\\Lib\\site-packages\\xgboost\\core.py:160: UserWarning: [16:40:40] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-0b3782d1791676daf-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:742: \n",
      "Parameters: { \"num_boost_round\", \"rate_drop\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 53%|█████▎    | 53/100 [06:01<04:08,  5.28s/trial, best loss: 28780.701695406886]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\CODE\\Lib\\site-packages\\xgboost\\core.py:160: UserWarning: [16:40:42] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-0b3782d1791676daf-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:742: \n",
      "Parameters: { \"num_boost_round\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 54%|█████▍    | 54/100 [06:04<03:26,  4.49s/trial, best loss: 28780.701695406886]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\CODE\\Lib\\site-packages\\xgboost\\core.py:160: UserWarning: [16:40:45] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-0b3782d1791676daf-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:742: \n",
      "Parameters: { \"num_boost_round\", \"rate_drop\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 55%|█████▌    | 55/100 [06:05<02:39,  3.55s/trial, best loss: 28780.701695406886]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\CODE\\Lib\\site-packages\\xgboost\\core.py:160: UserWarning: [16:40:46] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-0b3782d1791676daf-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:742: \n",
      "Parameters: { \"num_boost_round\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 56%|█████▌    | 56/100 [06:07<02:14,  3.06s/trial, best loss: 28780.701695406886]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\CODE\\Lib\\site-packages\\xgboost\\core.py:160: UserWarning: [16:40:48] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-0b3782d1791676daf-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:742: \n",
      "Parameters: { \"num_boost_round\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 57%|█████▋    | 57/100 [06:20<04:14,  5.93s/trial, best loss: 28780.701695406886]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\CODE\\Lib\\site-packages\\xgboost\\core.py:160: UserWarning: [16:41:01] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-0b3782d1791676daf-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:742: \n",
      "Parameters: { \"num_boost_round\", \"rate_drop\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 58%|█████▊    | 58/100 [06:22<03:20,  4.78s/trial, best loss: 28780.701695406886]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\CODE\\Lib\\site-packages\\xgboost\\core.py:160: UserWarning: [16:41:03] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-0b3782d1791676daf-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:742: \n",
      "Parameters: { \"num_boost_round\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 59%|█████▉    | 59/100 [06:26<03:04,  4.51s/trial, best loss: 28780.701695406886]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\CODE\\Lib\\site-packages\\xgboost\\core.py:160: UserWarning: [16:41:07] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-0b3782d1791676daf-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:742: \n",
      "Parameters: { \"num_boost_round\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 60%|██████    | 60/100 [06:35<03:58,  5.97s/trial, best loss: 28780.701695406886]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\CODE\\Lib\\site-packages\\xgboost\\core.py:160: UserWarning: [16:41:16] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-0b3782d1791676daf-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:742: \n",
      "Parameters: { \"num_boost_round\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 61%|██████    | 61/100 [06:46<04:54,  7.55s/trial, best loss: 28780.701695406886]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\CODE\\Lib\\site-packages\\xgboost\\core.py:160: UserWarning: [16:41:27] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-0b3782d1791676daf-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:742: \n",
      "Parameters: { \"num_boost_round\", \"rate_drop\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "\n",
      "d:\\CODE\\Lib\\site-packages\\numpy\\core\\_methods.py:236: RuntimeWarning: invalid value encountered in subtract\n",
      "  x = asanyarray(arr - arrmean)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 62%|██████▏   | 62/100 [06:48<03:43,  5.88s/trial, best loss: 28780.701695406886]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\CODE\\Lib\\site-packages\\xgboost\\core.py:160: UserWarning: [16:41:29] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-0b3782d1791676daf-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:742: \n",
      "Parameters: { \"num_boost_round\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 63%|██████▎   | 63/100 [06:54<03:32,  5.74s/trial, best loss: 28780.701695406886]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\CODE\\Lib\\site-packages\\xgboost\\core.py:160: UserWarning: [16:41:35] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-0b3782d1791676daf-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:742: \n",
      "Parameters: { \"num_boost_round\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 64%|██████▍   | 64/100 [07:04<04:12,  7.02s/trial, best loss: 28780.701695406886]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\CODE\\Lib\\site-packages\\xgboost\\core.py:160: UserWarning: [16:41:45] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-0b3782d1791676daf-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:742: \n",
      "Parameters: { \"num_boost_round\", \"rate_drop\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 65%|██████▌   | 65/100 [07:05<03:08,  5.38s/trial, best loss: 28780.701695406886]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\CODE\\Lib\\site-packages\\xgboost\\core.py:160: UserWarning: [16:41:46] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-0b3782d1791676daf-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:742: \n",
      "Parameters: { \"num_boost_round\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 66%|██████▌   | 66/100 [07:16<03:55,  6.94s/trial, best loss: 28780.701695406886]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\CODE\\Lib\\site-packages\\xgboost\\core.py:160: UserWarning: [16:41:57] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-0b3782d1791676daf-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:742: \n",
      "Parameters: { \"num_boost_round\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 67%|██████▋   | 67/100 [07:30<05:04,  9.23s/trial, best loss: 28780.701695406886]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\CODE\\Lib\\site-packages\\xgboost\\core.py:160: UserWarning: [16:42:11] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-0b3782d1791676daf-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:742: \n",
      "Parameters: { \"num_boost_round\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 68%|██████▊   | 68/100 [07:46<05:52, 11.01s/trial, best loss: 28285.66319140306] "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\CODE\\Lib\\site-packages\\xgboost\\core.py:160: UserWarning: [16:42:27] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-0b3782d1791676daf-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:742: \n",
      "Parameters: { \"num_boost_round\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 69%|██████▉   | 69/100 [08:01<06:19, 12.23s/trial, best loss: 28285.66319140306]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\CODE\\Lib\\site-packages\\xgboost\\core.py:160: UserWarning: [16:42:42] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-0b3782d1791676daf-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:742: \n",
      "Parameters: { \"num_boost_round\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 70%|███████   | 70/100 [08:14<06:19, 12.65s/trial, best loss: 28285.66319140306]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\CODE\\Lib\\site-packages\\xgboost\\core.py:160: UserWarning: [16:42:55] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-0b3782d1791676daf-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:742: \n",
      "Parameters: { \"num_boost_round\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 71%|███████   | 71/100 [08:29<06:23, 13.21s/trial, best loss: 28285.66319140306]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\CODE\\Lib\\site-packages\\xgboost\\core.py:160: UserWarning: [16:43:10] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-0b3782d1791676daf-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:742: \n",
      "Parameters: { \"num_boost_round\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 72%|███████▏  | 72/100 [08:42<06:12, 13.30s/trial, best loss: 28285.66319140306]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\CODE\\Lib\\site-packages\\xgboost\\core.py:160: UserWarning: [16:43:23] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-0b3782d1791676daf-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:742: \n",
      "Parameters: { \"num_boost_round\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 73%|███████▎  | 73/100 [08:57<06:06, 13.59s/trial, best loss: 28285.66319140306]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\CODE\\Lib\\site-packages\\xgboost\\core.py:160: UserWarning: [16:43:37] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-0b3782d1791676daf-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:742: \n",
      "Parameters: { \"num_boost_round\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 74%|███████▍  | 74/100 [09:09<05:45, 13.28s/trial, best loss: 28285.66319140306]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\CODE\\Lib\\site-packages\\xgboost\\core.py:160: UserWarning: [16:43:50] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-0b3782d1791676daf-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:742: \n",
      "Parameters: { \"num_boost_round\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 75%|███████▌  | 75/100 [09:20<05:10, 12.42s/trial, best loss: 28285.66319140306]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\CODE\\Lib\\site-packages\\xgboost\\core.py:160: UserWarning: [16:44:00] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-0b3782d1791676daf-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:742: \n",
      "Parameters: { \"num_boost_round\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 76%|███████▌  | 76/100 [09:33<05:08, 12.85s/trial, best loss: 28285.66319140306]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\CODE\\Lib\\site-packages\\xgboost\\core.py:160: UserWarning: [16:44:14] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-0b3782d1791676daf-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:742: \n",
      "Parameters: { \"num_boost_round\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 77%|███████▋  | 77/100 [09:45<04:47, 12.51s/trial, best loss: 28285.66319140306]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\CODE\\Lib\\site-packages\\xgboost\\core.py:160: UserWarning: [16:44:26] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-0b3782d1791676daf-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:742: \n",
      "Parameters: { \"num_boost_round\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 78%|███████▊  | 78/100 [09:54<04:08, 11.27s/trial, best loss: 28285.66319140306]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\CODE\\Lib\\site-packages\\xgboost\\core.py:160: UserWarning: [16:44:34] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-0b3782d1791676daf-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:742: \n",
      "Parameters: { \"num_boost_round\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 79%|███████▉  | 79/100 [09:57<03:08,  8.95s/trial, best loss: 28285.66319140306]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\CODE\\Lib\\site-packages\\xgboost\\core.py:160: UserWarning: [16:44:38] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-0b3782d1791676daf-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:742: \n",
      "Parameters: { \"num_boost_round\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 80%|████████  | 80/100 [10:11<03:26, 10.30s/trial, best loss: 28285.66319140306]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\CODE\\Lib\\site-packages\\xgboost\\core.py:160: UserWarning: [16:44:51] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-0b3782d1791676daf-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:742: \n",
      "Parameters: { \"num_boost_round\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 81%|████████  | 81/100 [10:25<03:40, 11.61s/trial, best loss: 28285.66319140306]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\CODE\\Lib\\site-packages\\xgboost\\core.py:160: UserWarning: [16:45:06] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-0b3782d1791676daf-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:742: \n",
      "Parameters: { \"num_boost_round\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 82%|████████▏ | 82/100 [10:35<03:18, 11.01s/trial, best loss: 28285.66319140306]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\CODE\\Lib\\site-packages\\xgboost\\core.py:160: UserWarning: [16:45:16] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-0b3782d1791676daf-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:742: \n",
      "Parameters: { \"num_boost_round\", \"rate_drop\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 83%|████████▎ | 83/100 [10:37<02:21,  8.30s/trial, best loss: 28285.66319140306]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\CODE\\Lib\\site-packages\\xgboost\\core.py:160: UserWarning: [16:45:18] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-0b3782d1791676daf-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:742: \n",
      "Parameters: { \"num_boost_round\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 84%|████████▍ | 84/100 [10:48<02:25,  9.09s/trial, best loss: 28285.66319140306]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\CODE\\Lib\\site-packages\\xgboost\\core.py:160: UserWarning: [16:45:29] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-0b3782d1791676daf-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:742: \n",
      "Parameters: { \"num_boost_round\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 85%|████████▌ | 85/100 [10:49<01:43,  6.87s/trial, best loss: 28285.66319140306]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\CODE\\Lib\\site-packages\\xgboost\\core.py:160: UserWarning: [16:45:30] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-0b3782d1791676daf-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:742: \n",
      "Parameters: { \"num_boost_round\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 86%|████████▌ | 86/100 [10:54<01:26,  6.15s/trial, best loss: 28285.66319140306]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\CODE\\Lib\\site-packages\\xgboost\\core.py:160: UserWarning: [16:45:35] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-0b3782d1791676daf-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:742: \n",
      "Parameters: { \"num_boost_round\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 87%|████████▋ | 87/100 [11:01<01:22,  6.31s/trial, best loss: 28285.66319140306]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\CODE\\Lib\\site-packages\\xgboost\\core.py:160: UserWarning: [16:45:41] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-0b3782d1791676daf-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:742: \n",
      "Parameters: { \"num_boost_round\", \"rate_drop\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 88%|████████▊ | 88/100 [11:01<00:56,  4.67s/trial, best loss: 28285.66319140306]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\CODE\\Lib\\site-packages\\xgboost\\core.py:160: UserWarning: [16:45:42] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-0b3782d1791676daf-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:742: \n",
      "Parameters: { \"num_boost_round\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 89%|████████▉ | 89/100 [11:07<00:54,  4.96s/trial, best loss: 28233.51446105525]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\CODE\\Lib\\site-packages\\xgboost\\core.py:160: UserWarning: [16:45:48] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-0b3782d1791676daf-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:742: \n",
      "Parameters: { \"num_boost_round\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 90%|█████████ | 90/100 [11:12<00:50,  5.06s/trial, best loss: 28233.51446105525]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\CODE\\Lib\\site-packages\\xgboost\\core.py:160: UserWarning: [16:45:53] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-0b3782d1791676daf-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:742: \n",
      "Parameters: { \"num_boost_round\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 91%|█████████ | 91/100 [11:17<00:44,  4.94s/trial, best loss: 28233.51446105525]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\CODE\\Lib\\site-packages\\xgboost\\core.py:160: UserWarning: [16:45:58] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-0b3782d1791676daf-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:742: \n",
      "Parameters: { \"num_boost_round\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 92%|█████████▏| 92/100 [11:24<00:44,  5.61s/trial, best loss: 28233.51446105525]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\CODE\\Lib\\site-packages\\xgboost\\core.py:160: UserWarning: [16:46:05] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-0b3782d1791676daf-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:742: \n",
      "Parameters: { \"num_boost_round\", \"rate_drop\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 93%|█████████▎| 93/100 [11:25<00:29,  4.28s/trial, best loss: 28233.51446105525]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\CODE\\Lib\\site-packages\\xgboost\\core.py:160: UserWarning: [16:46:06] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-0b3782d1791676daf-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:742: \n",
      "Parameters: { \"num_boost_round\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 94%|█████████▍| 94/100 [11:31<00:28,  4.76s/trial, best loss: 28233.51446105525]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\CODE\\Lib\\site-packages\\xgboost\\core.py:160: UserWarning: [16:46:12] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-0b3782d1791676daf-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:742: \n",
      "Parameters: { \"num_boost_round\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 95%|█████████▌| 95/100 [11:38<00:27,  5.41s/trial, best loss: 28233.51446105525]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\CODE\\Lib\\site-packages\\xgboost\\core.py:160: UserWarning: [16:46:19] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-0b3782d1791676daf-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:742: \n",
      "Parameters: { \"num_boost_round\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 96%|█████████▌| 96/100 [11:41<00:18,  4.65s/trial, best loss: 28233.51446105525]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\CODE\\Lib\\site-packages\\xgboost\\core.py:160: UserWarning: [16:46:22] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-0b3782d1791676daf-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:742: \n",
      "Parameters: { \"num_boost_round\", \"rate_drop\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 97%|█████████▋| 97/100 [11:42<00:10,  3.60s/trial, best loss: 28233.51446105525]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\CODE\\Lib\\site-packages\\xgboost\\core.py:160: UserWarning: [16:46:23] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-0b3782d1791676daf-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:742: \n",
      "Parameters: { \"num_boost_round\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 98%|█████████▊| 98/100 [11:44<00:06,  3.20s/trial, best loss: 28233.51446105525]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\CODE\\Lib\\site-packages\\xgboost\\core.py:160: UserWarning: [16:46:25] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-0b3782d1791676daf-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:742: \n",
      "Parameters: { \"num_boost_round\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 99%|█████████▉| 99/100 [11:46<00:02,  2.78s/trial, best loss: 28233.51446105525]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\CODE\\Lib\\site-packages\\xgboost\\core.py:160: UserWarning: [16:46:27] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-0b3782d1791676daf-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:742: \n",
      "Parameters: { \"num_boost_round\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100%|██████████| 100/100 [11:49<00:00,  7.09s/trial, best loss: 28233.51446105525]\n",
      "\n",
      " \n",
      " best params:  {'booster': 1, 'colsample_bynode': 0.30000000000000004, 'colsample_bytree': 0.5, 'eta': 0.9500000000000001, 'gamma': 4000000.0, 'lambda': 2.4000000000000004, 'max_depth': 4, 'min_child_weight': 18.0, 'num_boost_round': 110.0, 'objective': 0, 'rate_drop': 0.1, 'subsample': 0.7000000000000001} \n",
      "\n"
     ]
    }
   ],
   "source": [
    "params_best, trials = param_hyperopt(100) #由于参数空间巨大，给与100次迭代的空间"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "best params:  {'booster': 1, 'colsample_bynode': 0.30000000000000004, 'colsample_bytree': 0.5, 'eta': 0.9500000000000001, 'gamma': 4000000.0, 'lambda': 2.4000000000000004, 'max_depth': 4, 'min_child_weight': 18.0, 'num_boost_round': 110.0, 'objective': 0, 'rate_drop': 0.1, 'subsample': 0.7000000000000001} \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_grid_simple = {'num_boost_round': hp.quniform(\"num_boost_round\",100,300,10)\n",
    "                     ,\"eta\": hp.quniform(\"eta\",0.05,2.05,0.05)\n",
    "                     ,\"colsample_bytree\":hp.quniform(\"colsample_bytree\",0.5,1,0.05)\n",
    "                     ,\"colsample_bynode\":hp.quniform(\"colsample_bynode\",0.3,1,0.05)\n",
    "                     ,\"gamma\":hp.quniform(\"gamma\",5e6,1.5e7,5e5)\n",
    "                     ,\"lambda\":hp.quniform(\"lambda\",0,2,0.1)\n",
    "                     ,\"min_child_weight\":hp.quniform(\"min_child_weight\",0,10,0.5)\n",
    "                     ,\"max_depth\":hp.choice(\"max_depth\",[*range(2,15,1)])\n",
    "                     ,\"subsample\":hp.quniform(\"subsample\",0.5,1,0.05)\n",
    "                     ,\"rate_drop\":hp.quniform(\"rate_drop\",0.1,1,0.05)\n",
    "                    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def hyperopt_objective(params):\n",
    "    paramsforxgb = {\"eta\":params[\"eta\"]\n",
    "                    ,\"colsample_bytree\":params[\"colsample_bytree\"]\n",
    "                    ,\"colsample_bynode\":params[\"colsample_bynode\"]\n",
    "                    ,\"gamma\":params[\"gamma\"]\n",
    "                    ,\"lambda\":params[\"lambda\"]\n",
    "                    ,\"min_child_weight\":params[\"min_child_weight\"]\n",
    "                    ,\"max_depth\":int(params[\"max_depth\"])\n",
    "                    ,\"subsample\":params[\"subsample\"]\n",
    "                    ,\"rate_drop\":params[\"rate_drop\"]\n",
    "                    ,\"booster\":\"dart\"\n",
    "                    ,\"nthred\":14\n",
    "                    ,\"verbosity\":0\n",
    "                    ,\"seed\":1412}\n",
    "    result = xgb.cv(params,data_xgb, seed=1412, metrics=(\"rmse\")\n",
    "                    ,num_boost_round=int(params[\"num_boost_round\"]))\n",
    "    return result.iloc[-1,2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/100 [00:00<?, ?trial/s, best loss=?]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\CODE\\Lib\\site-packages\\xgboost\\core.py:160: UserWarning: [16:47:51] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-0b3782d1791676daf-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:742: \n",
      "Parameters: { \"num_boost_round\", \"rate_drop\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  1%|          | 1/100 [00:02<04:56,  3.00s/trial, best loss: 35791.963744075634]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\CODE\\Lib\\site-packages\\xgboost\\core.py:160: UserWarning: [16:47:54] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-0b3782d1791676daf-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:742: \n",
      "Parameters: { \"num_boost_round\", \"rate_drop\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  2%|▏         | 2/100 [00:06<05:27,  3.34s/trial, best loss: 35791.963744075634]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\CODE\\Lib\\site-packages\\xgboost\\core.py:160: UserWarning: [16:47:58] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-0b3782d1791676daf-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:742: \n",
      "Parameters: { \"num_boost_round\", \"rate_drop\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  3%|▎         | 3/100 [00:09<04:48,  2.98s/trial, best loss: 32644.356973806203]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\CODE\\Lib\\site-packages\\xgboost\\core.py:160: UserWarning: [16:48:00] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-0b3782d1791676daf-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:742: \n",
      "Parameters: { \"num_boost_round\", \"rate_drop\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  4%|▍         | 4/100 [00:10<03:47,  2.36s/trial, best loss: 29707.42589223424] "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\CODE\\Lib\\site-packages\\xgboost\\core.py:160: UserWarning: [16:48:02] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-0b3782d1791676daf-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:742: \n",
      "Parameters: { \"num_boost_round\", \"rate_drop\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  5%|▌         | 5/100 [00:12<03:14,  2.04s/trial, best loss: 29707.42589223424]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\CODE\\Lib\\site-packages\\xgboost\\core.py:160: UserWarning: [16:48:03] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-0b3782d1791676daf-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:742: \n",
      "Parameters: { \"num_boost_round\", \"rate_drop\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  6%|▌         | 6/100 [00:13<02:44,  1.75s/trial, best loss: 29707.42589223424]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\CODE\\Lib\\site-packages\\xgboost\\core.py:160: UserWarning: [16:48:04] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-0b3782d1791676daf-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:742: \n",
      "Parameters: { \"num_boost_round\", \"rate_drop\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  7%|▋         | 7/100 [00:14<02:24,  1.56s/trial, best loss: 29707.42589223424]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\CODE\\Lib\\site-packages\\xgboost\\core.py:160: UserWarning: [16:48:05] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-0b3782d1791676daf-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:742: \n",
      "Parameters: { \"num_boost_round\", \"rate_drop\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  8%|▊         | 8/100 [00:17<02:56,  1.92s/trial, best loss: 29707.42589223424]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\CODE\\Lib\\site-packages\\xgboost\\core.py:160: UserWarning: [16:48:08] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-0b3782d1791676daf-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:742: \n",
      "Parameters: { \"num_boost_round\", \"rate_drop\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  9%|▉         | 9/100 [00:18<02:43,  1.80s/trial, best loss: 29707.42589223424]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\CODE\\Lib\\site-packages\\xgboost\\core.py:160: UserWarning: [16:48:10] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-0b3782d1791676daf-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:742: \n",
      "Parameters: { \"num_boost_round\", \"rate_drop\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 10%|█         | 10/100 [00:20<02:32,  1.69s/trial, best loss: 29707.42589223424]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\CODE\\Lib\\site-packages\\xgboost\\core.py:160: UserWarning: [16:48:11] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-0b3782d1791676daf-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:742: \n",
      "Parameters: { \"num_boost_round\", \"rate_drop\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 11%|█         | 11/100 [00:22<02:38,  1.78s/trial, best loss: 29707.42589223424]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\CODE\\Lib\\site-packages\\xgboost\\core.py:160: UserWarning: [16:48:13] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-0b3782d1791676daf-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:742: \n",
      "Parameters: { \"num_boost_round\", \"rate_drop\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 12%|█▏        | 12/100 [00:23<02:31,  1.72s/trial, best loss: 29707.42589223424]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\CODE\\Lib\\site-packages\\xgboost\\core.py:160: UserWarning: [16:48:15] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-0b3782d1791676daf-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:742: \n",
      "Parameters: { \"num_boost_round\", \"rate_drop\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 13%|█▎        | 13/100 [00:24<02:14,  1.55s/trial, best loss: 29707.42589223424]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\CODE\\Lib\\site-packages\\xgboost\\core.py:160: UserWarning: [16:48:16] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-0b3782d1791676daf-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:742: \n",
      "Parameters: { \"num_boost_round\", \"rate_drop\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 14%|█▍        | 14/100 [00:25<02:01,  1.41s/trial, best loss: 29707.42589223424]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\CODE\\Lib\\site-packages\\xgboost\\core.py:160: UserWarning: [16:48:17] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-0b3782d1791676daf-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:742: \n",
      "Parameters: { \"num_boost_round\", \"rate_drop\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 15%|█▌        | 15/100 [00:27<02:03,  1.45s/trial, best loss: 29707.42589223424]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\CODE\\Lib\\site-packages\\xgboost\\core.py:160: UserWarning: [16:48:18] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-0b3782d1791676daf-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:742: \n",
      "Parameters: { \"num_boost_round\", \"rate_drop\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 16%|█▌        | 16/100 [00:30<02:37,  1.88s/trial, best loss: 29707.42589223424]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\CODE\\Lib\\site-packages\\xgboost\\core.py:160: UserWarning: [16:48:21] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-0b3782d1791676daf-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:742: \n",
      "Parameters: { \"num_boost_round\", \"rate_drop\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 17%|█▋        | 17/100 [00:33<02:59,  2.16s/trial, best loss: 29707.42589223424]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\CODE\\Lib\\site-packages\\xgboost\\core.py:160: UserWarning: [16:48:24] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-0b3782d1791676daf-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:742: \n",
      "Parameters: { \"num_boost_round\", \"rate_drop\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 18%|█▊        | 18/100 [00:35<03:12,  2.35s/trial, best loss: 29707.42589223424]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\CODE\\Lib\\site-packages\\xgboost\\core.py:160: UserWarning: [16:48:27] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-0b3782d1791676daf-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:742: \n",
      "Parameters: { \"num_boost_round\", \"rate_drop\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 19%|█▉        | 19/100 [00:36<02:40,  1.98s/trial, best loss: 29707.42589223424]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\CODE\\Lib\\site-packages\\xgboost\\core.py:160: UserWarning: [16:48:28] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-0b3782d1791676daf-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:742: \n",
      "Parameters: { \"num_boost_round\", \"rate_drop\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 20%|██        | 20/100 [00:39<03:02,  2.28s/trial, best loss: 29707.42589223424]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\CODE\\Lib\\site-packages\\xgboost\\core.py:160: UserWarning: [16:48:31] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-0b3782d1791676daf-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:742: \n",
      "Parameters: { \"num_boost_round\", \"rate_drop\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 21%|██        | 21/100 [00:42<03:08,  2.38s/trial, best loss: 28016.88085187094]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\CODE\\Lib\\site-packages\\xgboost\\core.py:160: UserWarning: [16:48:34] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-0b3782d1791676daf-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:742: \n",
      "Parameters: { \"num_boost_round\", \"rate_drop\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 22%|██▏       | 22/100 [00:44<03:02,  2.34s/trial, best loss: 28016.88085187094]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\CODE\\Lib\\site-packages\\xgboost\\core.py:160: UserWarning: [16:48:36] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-0b3782d1791676daf-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:742: \n",
      "Parameters: { \"num_boost_round\", \"rate_drop\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 23%|██▎       | 23/100 [00:47<03:01,  2.35s/trial, best loss: 27744.00237455608]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\CODE\\Lib\\site-packages\\xgboost\\core.py:160: UserWarning: [16:48:38] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-0b3782d1791676daf-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:742: \n",
      "Parameters: { \"num_boost_round\", \"rate_drop\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 24%|██▍       | 24/100 [00:50<03:14,  2.56s/trial, best loss: 27744.00237455608]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\CODE\\Lib\\site-packages\\xgboost\\core.py:160: UserWarning: [16:48:41] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-0b3782d1791676daf-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:742: \n",
      "Parameters: { \"num_boost_round\", \"rate_drop\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 25%|██▌       | 25/100 [00:53<03:30,  2.81s/trial, best loss: 26815.65123756498]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\CODE\\Lib\\site-packages\\xgboost\\core.py:160: UserWarning: [16:48:45] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-0b3782d1791676daf-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:742: \n",
      "Parameters: { \"num_boost_round\", \"rate_drop\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 26%|██▌       | 26/100 [00:57<03:46,  3.06s/trial, best loss: 26815.65123756498]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\CODE\\Lib\\site-packages\\xgboost\\core.py:160: UserWarning: [16:48:48] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-0b3782d1791676daf-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:742: \n",
      "Parameters: { \"num_boost_round\", \"rate_drop\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 27%|██▋       | 27/100 [01:00<03:40,  3.02s/trial, best loss: 26815.65123756498]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\CODE\\Lib\\site-packages\\xgboost\\core.py:160: UserWarning: [16:48:51] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-0b3782d1791676daf-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:742: \n",
      "Parameters: { \"num_boost_round\", \"rate_drop\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 28%|██▊       | 28/100 [01:02<03:22,  2.81s/trial, best loss: 26815.65123756498]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\CODE\\Lib\\site-packages\\xgboost\\core.py:160: UserWarning: [16:48:54] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-0b3782d1791676daf-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:742: \n",
      "Parameters: { \"num_boost_round\", \"rate_drop\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 29%|██▉       | 29/100 [01:05<03:12,  2.71s/trial, best loss: 26815.65123756498]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\CODE\\Lib\\site-packages\\xgboost\\core.py:160: UserWarning: [16:48:56] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-0b3782d1791676daf-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:742: \n",
      "Parameters: { \"num_boost_round\", \"rate_drop\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 30%|███       | 30/100 [01:07<02:59,  2.57s/trial, best loss: 26815.65123756498]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\CODE\\Lib\\site-packages\\xgboost\\core.py:160: UserWarning: [16:48:58] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-0b3782d1791676daf-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:742: \n",
      "Parameters: { \"num_boost_round\", \"rate_drop\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 31%|███       | 31/100 [01:09<02:54,  2.53s/trial, best loss: 26815.65123756498]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\CODE\\Lib\\site-packages\\xgboost\\core.py:160: UserWarning: [16:49:01] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-0b3782d1791676daf-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:742: \n",
      "Parameters: { \"num_boost_round\", \"rate_drop\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 32%|███▏      | 32/100 [01:13<03:21,  2.96s/trial, best loss: 26815.65123756498]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\CODE\\Lib\\site-packages\\xgboost\\core.py:160: UserWarning: [16:49:05] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-0b3782d1791676daf-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:742: \n",
      "Parameters: { \"num_boost_round\", \"rate_drop\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 33%|███▎      | 33/100 [01:16<03:06,  2.79s/trial, best loss: 26815.65123756498]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\CODE\\Lib\\site-packages\\xgboost\\core.py:160: UserWarning: [16:49:07] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-0b3782d1791676daf-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:742: \n",
      "Parameters: { \"num_boost_round\", \"rate_drop\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 34%|███▍      | 34/100 [01:18<03:04,  2.79s/trial, best loss: 26815.65123756498]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\CODE\\Lib\\site-packages\\xgboost\\core.py:160: UserWarning: [16:49:10] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-0b3782d1791676daf-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:742: \n",
      "Parameters: { \"num_boost_round\", \"rate_drop\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 35%|███▌      | 35/100 [01:20<02:39,  2.45s/trial, best loss: 26815.65123756498]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\CODE\\Lib\\site-packages\\xgboost\\core.py:160: UserWarning: [16:49:12] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-0b3782d1791676daf-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:742: \n",
      "Parameters: { \"num_boost_round\", \"rate_drop\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 36%|███▌      | 36/100 [01:22<02:27,  2.31s/trial, best loss: 26815.65123756498]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\CODE\\Lib\\site-packages\\xgboost\\core.py:160: UserWarning: [16:49:14] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-0b3782d1791676daf-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:742: \n",
      "Parameters: { \"num_boost_round\", \"rate_drop\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 37%|███▋      | 37/100 [01:25<02:30,  2.39s/trial, best loss: 26815.65123756498]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\CODE\\Lib\\site-packages\\xgboost\\core.py:160: UserWarning: [16:49:16] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-0b3782d1791676daf-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:742: \n",
      "Parameters: { \"num_boost_round\", \"rate_drop\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 38%|███▊      | 38/100 [01:27<02:26,  2.36s/trial, best loss: 26815.65123756498]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\CODE\\Lib\\site-packages\\xgboost\\core.py:160: UserWarning: [16:49:18] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-0b3782d1791676daf-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:742: \n",
      "Parameters: { \"num_boost_round\", \"rate_drop\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "\n",
      "d:\\CODE\\Lib\\site-packages\\xgboost\\core.py:160: UserWarning: [16:49:19] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-0b3782d1791676daf-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:742: \n",
      "Parameters: { \"num_boost_round\", \"rate_drop\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 39%|███▉      | 39/100 [01:31<02:54,  2.86s/trial, best loss: 26815.65123756498]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\CODE\\Lib\\site-packages\\xgboost\\core.py:160: UserWarning: [16:49:22] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-0b3782d1791676daf-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:742: \n",
      "Parameters: { \"num_boost_round\", \"rate_drop\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "\n",
      "d:\\CODE\\Lib\\site-packages\\xgboost\\core.py:160: UserWarning: [16:49:23] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-0b3782d1791676daf-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:742: \n",
      "Parameters: { \"num_boost_round\", \"rate_drop\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 40%|████      | 40/100 [01:33<02:34,  2.57s/trial, best loss: 26815.65123756498]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\CODE\\Lib\\site-packages\\xgboost\\core.py:160: UserWarning: [16:49:24] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-0b3782d1791676daf-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:742: \n",
      "Parameters: { \"num_boost_round\", \"rate_drop\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 41%|████      | 41/100 [01:35<02:31,  2.57s/trial, best loss: 26815.65123756498]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\CODE\\Lib\\site-packages\\xgboost\\core.py:160: UserWarning: [16:49:27] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-0b3782d1791676daf-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:742: \n",
      "Parameters: { \"num_boost_round\", \"rate_drop\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 42%|████▏     | 42/100 [01:38<02:23,  2.48s/trial, best loss: 26815.65123756498]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\CODE\\Lib\\site-packages\\xgboost\\core.py:160: UserWarning: [16:49:29] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-0b3782d1791676daf-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:742: \n",
      "Parameters: { \"num_boost_round\", \"rate_drop\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 43%|████▎     | 43/100 [01:40<02:13,  2.35s/trial, best loss: 26815.65123756498]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\CODE\\Lib\\site-packages\\xgboost\\core.py:160: UserWarning: [16:49:31] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-0b3782d1791676daf-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:742: \n",
      "Parameters: { \"num_boost_round\", \"rate_drop\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 44%|████▍     | 44/100 [01:42<02:18,  2.47s/trial, best loss: 26815.65123756498]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\CODE\\Lib\\site-packages\\xgboost\\core.py:160: UserWarning: [16:49:34] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-0b3782d1791676daf-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:742: \n",
      "Parameters: { \"num_boost_round\", \"rate_drop\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 45%|████▌     | 45/100 [01:44<02:00,  2.19s/trial, best loss: 26815.65123756498]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\CODE\\Lib\\site-packages\\xgboost\\core.py:160: UserWarning: [16:49:36] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-0b3782d1791676daf-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:742: \n",
      "Parameters: { \"num_boost_round\", \"rate_drop\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 46%|████▌     | 46/100 [01:46<02:00,  2.23s/trial, best loss: 26815.65123756498]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\CODE\\Lib\\site-packages\\xgboost\\core.py:160: UserWarning: [16:49:38] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-0b3782d1791676daf-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:742: \n",
      "Parameters: { \"num_boost_round\", \"rate_drop\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 47%|████▋     | 47/100 [01:49<02:12,  2.49s/trial, best loss: 26815.65123756498]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\CODE\\Lib\\site-packages\\xgboost\\core.py:160: UserWarning: [16:49:41] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-0b3782d1791676daf-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:742: \n",
      "Parameters: { \"num_boost_round\", \"rate_drop\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 48%|████▊     | 48/100 [01:51<01:59,  2.30s/trial, best loss: 26815.65123756498]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\CODE\\Lib\\site-packages\\xgboost\\core.py:160: UserWarning: [16:49:43] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-0b3782d1791676daf-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:742: \n",
      "Parameters: { \"num_boost_round\", \"rate_drop\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 49%|████▉     | 49/100 [01:53<01:56,  2.28s/trial, best loss: 26815.65123756498]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\CODE\\Lib\\site-packages\\xgboost\\core.py:160: UserWarning: [16:49:45] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-0b3782d1791676daf-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:742: \n",
      "Parameters: { \"num_boost_round\", \"rate_drop\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 50%|█████     | 50/100 [01:56<01:54,  2.29s/trial, best loss: 26815.65123756498]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\CODE\\Lib\\site-packages\\xgboost\\core.py:160: UserWarning: [16:49:47] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-0b3782d1791676daf-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:742: \n",
      "Parameters: { \"num_boost_round\", \"rate_drop\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 51%|█████     | 51/100 [01:59<01:58,  2.42s/trial, best loss: 26815.65123756498]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\CODE\\Lib\\site-packages\\xgboost\\core.py:160: UserWarning: [16:49:50] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-0b3782d1791676daf-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:742: \n",
      "Parameters: { \"num_boost_round\", \"rate_drop\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 52%|█████▏    | 52/100 [02:01<02:03,  2.58s/trial, best loss: 26815.65123756498]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\CODE\\Lib\\site-packages\\xgboost\\core.py:160: UserWarning: [16:49:53] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-0b3782d1791676daf-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:742: \n",
      "Parameters: { \"num_boost_round\", \"rate_drop\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 53%|█████▎    | 53/100 [02:04<02:07,  2.71s/trial, best loss: 26815.65123756498]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\CODE\\Lib\\site-packages\\xgboost\\core.py:160: UserWarning: [16:49:56] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-0b3782d1791676daf-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:742: \n",
      "Parameters: { \"num_boost_round\", \"rate_drop\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 54%|█████▍    | 54/100 [02:06<01:54,  2.49s/trial, best loss: 26815.65123756498]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\CODE\\Lib\\site-packages\\xgboost\\core.py:160: UserWarning: [16:49:58] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-0b3782d1791676daf-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:742: \n",
      "Parameters: { \"num_boost_round\", \"rate_drop\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 55%|█████▌    | 55/100 [02:08<01:45,  2.34s/trial, best loss: 26815.65123756498]\n",
      "\n",
      " \n",
      " best params:  {'colsample_bynode': 0.6000000000000001, 'colsample_bytree': 0.6000000000000001, 'eta': 0.05, 'gamma': 13500000.0, 'lambda': 2.0, 'max_depth': 10, 'min_child_weight': 6.0, 'num_boost_round': 230.0, 'rate_drop': 0.2, 'subsample': 0.8} \n",
      "\n"
     ]
    }
   ],
   "source": [
    "params_best, trials = param_hyperopt(100) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "best params:  {'colsample_bynode': 0.6000000000000001, 'colsample_bytree': 0.6000000000000001, 'eta': 0.05, 'gamma': 13500000.0, 'lambda': 2.0, 'max_depth': 10, 'min_child_weight': 6.0, 'num_boost_round': 230.0, 'rate_drop': 0.2, 'subsample': 0.8}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "bestparams = {'colsample_bynode': 0.6000000000000001,\n",
    "               'colsample_bytree': 0.6000000000000001,\n",
    "                 'eta': 0.05,\n",
    "                   'gamma': 13500000.0,\n",
    "                     'lambda': 2.0, 'max_depth': 10,\n",
    "                       'min_child_weight': 6.0,\n",
    "                         'num_boost_round': 230.0, \n",
    "                         'rate_drop': 0.2,\n",
    "                           'subsample': 0.8}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\CODE\\Lib\\site-packages\\xgboost\\core.py:160: UserWarning: [16:52:17] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-0b3782d1791676daf-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:742: \n",
      "Parameters: { \"num_boost_round\", \"rate_drop\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "27457.66012559651"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def hyperopt_validation(params):\n",
    "    paramsforxgb = {\"eta\":params[\"eta\"]\n",
    "                    ,\"booster\":\"dart\"\n",
    "                    ,\"colsample_bytree\":params[\"colsample_bytree\"]\n",
    "                    ,\"colsample_bynode\":params[\"colsample_bynode\"]\n",
    "                    ,\"gamma\":params[\"gamma\"]\n",
    "                    ,\"lambda\":params[\"lambda\"]\n",
    "                    ,\"min_child_weight\":params[\"min_child_weight\"]\n",
    "                    ,\"max_depth\":int(params[\"max_depth\"])\n",
    "                    ,\"subsample\":params[\"subsample\"]\n",
    "                    ,\"rate_drop\":params[\"rate_drop\"]\n",
    "                    ,\"nthred\":14\n",
    "                    ,\"verbosity\":0\n",
    "                    ,\"seed\":1412}\n",
    "    result = xgb.cv(params,data_xgb, seed=1412, metrics=(\"rmse\")\n",
    "                    ,num_boost_round=int(params[\"num_boost_round\"]))\n",
    "    return result.iloc[-1,2]\n",
    "\n",
    "hyperopt_validation(bestparams)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "27457.66012559651"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "《XGBoost：一种可拓展的提升树系统》\n",
    "Chen,T.Q.; Geustrin, C. (2014). \"XGBoost: A Scalable Tree Boosting System\"\n",
    "\n",
    "《DART树：当Dropout遇见自适应回归树》\n",
    "Rashmi, K.V.; Ran Gilad-Bachrach.(2015) “DART: Dropouts meet Multiple Additive Regression Trees”\n",
    "\n",
    "《Lightgbm：一种极度高效的梯度提升树》\n",
    "Ke, G. et al.(2017).\"Lightgbm: A highly efficient gradient boosting decision tree\"\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
